{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3fed985e",
   "metadata": {},
   "source": [
    "该代码实现了DNN模型下bankmarketing数据集使用LLDP安全聚合策略进行拆分学习隐语实现,并与隐语银行营销内置dp策略进行了实验对比。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6fd22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Ant Group Co., Ltd.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Author: Yuanran Song\n",
    "# E-mail: 809127446@qq.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a98eed-3e6b-4e4f-94ae-54df2f500d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address='local')\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3bb959-2f56-4f8c-b0b0-575fa8b310fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "联邦表定义/数据预处理以及训练集和测试集的划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b7c19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.utils.simulation.datasets import dataset\n",
    "\n",
    "df = pd.read_csv(dataset('bank_marketing'), sep=';')\n",
    "print(df)\n",
    "alice_data = df[[\"age\",\"job\", \"marital\", \"education\", \"y\"]]\n",
    "alice_data\n",
    "print(alice_data)\n",
    "bob_data = df[[\"default\", \"balance\", \"housing\", \"loan\", \"contact\",\n",
    "        \"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\"]]\n",
    "bob_data\n",
    "from secretflow.data.split import train_test_split\n",
    "from secretflow.ml.nn import SLModel\n",
    "# spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))\n",
    "from secretflow.utils.simulation.datasets import load_bank_marketing\n",
    "\n",
    "# Alice has the first four features,\n",
    "# while bob has the laaaeft features\n",
    "data = load_bank_marketing(parts={alice: (0, 4), bob: (4, 16)}, axis=1)##alice取四维数据 bob取12维数据\n",
    "# Alice holds the label.\n",
    "label = load_bank_marketing(parts={alice: (16, 17)}, axis=1)##alice拥有所有标签\n",
    "print(data['age'].partitions[alice].data)##partition都会有自己的device归属，只有归属的device才可以操作数据\n",
    "# print(data['age'].partitions[bob])\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.encoder import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['job'] = encoder.fit_transform(data['job'])\n",
    "data['marital'] = encoder.fit_transform(data['marital'])\n",
    "data['education'] = encoder.fit_transform(data['education'])\n",
    "data['default'] = encoder.fit_transform(data['default'])\n",
    "data['housing'] = encoder.fit_transform(data['housing'])\n",
    "data['loan'] = encoder.fit_transform(data['loan'])\n",
    "data['contact'] = encoder.fit_transform(data['contact'])\n",
    "data['poutcome'] = encoder.fit_transform(data['poutcome'])\n",
    "data['month'] = encoder.fit_transform(data['month'])\n",
    "label = encoder.fit_transform(label)\n",
    "print(f\"label= {type(label)},\\ndata = {type(data)}\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "from secretflow.data.split import train_test_split\n",
    "random_state = 1234\n",
    "train_data,test_data = train_test_split(data, train_size=0.8, random_state=random_state)\n",
    "train_label,test_label = train_test_split(label, train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fab22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "创建垂直拆分场景的双方本地模型base_model和有label方持有的fuse_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d3ec1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_dim, output_dim,  name='base_model'):\n",
    "    # Create model\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_dim),\n",
    "                layers.Dense(100,activation =\"relu\" ),\n",
    "                layers.Dense(output_dim, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "    return create_model\n",
    "# prepare model\n",
    "hidden_size = 64\n",
    "alice_input_feature_num = train_data.values.partition_shape()[alice][1]\n",
    "bob_input_feature_num = train_data.values.partition_shape()[bob][1]\n",
    "\n",
    "model_base_alice = create_base_model(alice_input_feature_num, hidden_size)\n",
    "model_base_bob = create_base_model(bob_input_feature_num, hidden_size)\n",
    "model_base_alice()\n",
    "model_base_bob()\n",
    "def create_fuse_model(input_dim, output_dim, party_nums, name='fuse_model'):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        # input\n",
    "        input_layers = []\n",
    "        for i in range(party_nums):\n",
    "            input_layers.append(keras.Input(input_dim,))\n",
    "\n",
    "        merged_layer = layers.concatenate(input_layers)\n",
    "        fuse_layer = layers.Dense(64, activation='relu')(merged_layer)\n",
    "        output = layers.Dense(output_dim, activation='sigmoid')(fuse_layer)\n",
    "\n",
    "        model = keras.Model(inputs=input_layers, outputs=output)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "    return create_model\n",
    "model_fuse = create_fuse_model(\n",
    "    input_dim=hidden_size, party_nums=2, output_dim=1)\n",
    "model_fuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2882f401",
   "metadata": {},
   "source": [
    "接下来定义lldp_strategy，我们可以使用其对base_model与fuse_model实现逐层差分隐私加噪。其相较于隐语内置dp_strategy里的embedding_dp（embedding层加噪）与label_dp（标签加噪）相比。使用LLDP策略的全局模型具有更快的收敛速度和更高的预测准确性。这些改进来自于LLDP算法中对隐私预算进行了层次化的分配。实验结果会于代码末尾附上。以下代码给出fuse_model进行加噪的例子，往函数中输入base_model也可实现对本地模型的加噪策略。用户可根据隐私保护需求自由选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c57c83be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lldp_strategy(model):\n",
    "    model_data_list = model().get_weights()\n",
    "    print(model_data_list)\n",
    "    delta = math.exp(-3)\n",
    "    epsilon = [80, 80, 40, 40, 30, 30]  ##对三层模型进行加噪\n",
    "    for i in range(len(model_data_list)):\n",
    "        sigma = math.sqrt(2 * math.log(1.25 / delta)) / epsilon[i]\n",
    "        # print(\"sigma:\", sigma)\n",
    "        noise = np.random.normal(0, sigma, model_data_list[i].shape)\n",
    "        # add_noise\n",
    "        model_data_list[i] = model_data_list[i] + noise\n",
    "    model().set_weights(model_data_list)\n",
    "    return model\n",
    "model_fuse= create_lldp_strategy(model_fuse)\n",
    "model_fuse()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8a7f56",
   "metadata": {},
   "source": [
    "创建拆分学习模型，初始化SLModel的三个参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b298ac71",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model_dict = {\n",
    "    alice: model_base_alice,\n",
    "    bob:   model_base_bob\n",
    "}\n",
    "\n",
    "\n",
    "train_batch_size = 128\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=alice,\n",
    "    model_fuse=model_fuse,)\n",
    "    # dp_strategy_dict=dp_strategy_dict,)\n",
    "\n",
    "sf.reveal(test_data.partitions[alice].data), sf.reveal(test_label.partitions[alice].data)\n",
    "sf.reveal(train_data.partitions[alice].data), sf.reveal(train_label.partitions[alice].data)\n",
    "history =  sl_model.fit(train_data,\n",
    "             train_label,\n",
    "             validation_data=(test_data,test_label),\n",
    "             epochs=20,\n",
    "             batch_size=train_batch_size,\n",
    "             shuffle=True,\n",
    "             verbose=1,\n",
    "             validation_freq=1,)\n",
    "             # dp_spent_step_freq=dp_spent_step_freq,)\n",
    "print(history)\n",
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68c07e87",
   "metadata": {},
   "source": [
    "画出精确度、损失与AUC图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1bc1b76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot the change of loss during training\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1137af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change of accuracy during training\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41b31248",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the Area Under Curve(AUC) of loss during training\n",
    "plt.plot(history['train_auc_1'])\n",
    "plt.plot(history['val_auc_1'])\n",
    "plt.title('Model Area Under Curve')\n",
    "plt.ylabel('Area Under Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "global_metric = sl_model.evaluate(test_data, test_label, batch_size=128)\n",
    "print(global_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca538af-5979-46ca-a25a-0936565d09c3",
   "metadata": {},
   "source": [
    "将隐语拆分学习银行营销作为baseline，进行对比实验"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ec0ab1-e384-47b4-a2fd-519995f6859b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address='local')\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "import pandas as pd\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "\n",
    "df = pd.read_csv(dataset('bank_marketing'), sep=';')\n",
    "print(df)\n",
    "alice_data = df[[\"age\",\"job\", \"marital\", \"education\", \"y\"]]\n",
    "alice_data\n",
    "print(alice_data)\n",
    "bob_data = df[[\"default\", \"balance\", \"housing\", \"loan\", \"contact\",\n",
    "        \"day\",\"month\",\"duration\",\"campaign\",\"pdays\",\"previous\",\"poutcome\"]]\n",
    "bob_data\n",
    "from secretflow.data.split import train_test_split\n",
    "from secretflow.ml.nn import SLModel\n",
    "# spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))\n",
    "from secretflow.utils.simulation.datasets import load_bank_marketing\n",
    "\n",
    "# Alice has the first four features,\n",
    "# while bob has the laaaeft features\n",
    "data = load_bank_marketing(parts={alice: (0, 4), bob: (4, 16)}, axis=1)##alice取四维数据 bob取12维数据\n",
    "# Alice holds the label.\n",
    "label = load_bank_marketing(parts={alice: (16, 17)}, axis=1)##alice拥有所有标签\n",
    "print(data['age'].partitions[alice].data)##partition都会有自己的device归属，只有归属的device才可以操作数据\n",
    "# print(data['age'].partitions[bob])\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.encoder import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['job'] = encoder.fit_transform(data['job'])\n",
    "data['marital'] = encoder.fit_transform(data['marital'])\n",
    "data['education'] = encoder.fit_transform(data['education'])\n",
    "data['default'] = encoder.fit_transform(data['default'])\n",
    "data['housing'] = encoder.fit_transform(data['housing'])\n",
    "data['loan'] = encoder.fit_transform(data['loan'])\n",
    "data['contact'] = encoder.fit_transform(data['contact'])\n",
    "data['poutcome'] = encoder.fit_transform(data['poutcome'])\n",
    "data['month'] = encoder.fit_transform(data['month'])\n",
    "label = encoder.fit_transform(label)\n",
    "print(f\"label= {type(label)},\\ndata = {type(data)}\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "from secretflow.data.split import train_test_split\n",
    "random_state = 1234\n",
    "train_data,test_data = train_test_split(data, train_size=0.8, random_state=random_state)\n",
    "train_label,test_label = train_test_split(label, train_size=0.8, random_state=random_state)\n",
    "def create_base_model(input_dim, output_dim,  name='base_model'):\n",
    "    # Create model\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_dim),\n",
    "                layers.Dense(100,activation =\"relu\" ),\n",
    "                layers.Dense(output_dim, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "    return create_model\n",
    "\n",
    "\n",
    "hidden_size = 64\n",
    "\n",
    "model_base_alice = create_base_model(4, hidden_size)\n",
    "model_base_bob = create_base_model(12, hidden_size)\n",
    "model_base_alice()\n",
    "model_base_bob()\n",
    "\n",
    "def create_fuse_model(input_dim, output_dim, party_nums, name='fuse_model'):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        # input\n",
    "        input_layers = []\n",
    "        for i in range(party_nums):\n",
    "            input_layers.append(keras.Input(input_dim, ))\n",
    "\n",
    "        merged_layer = layers.concatenate(input_layers)\n",
    "        fuse_layer = layers.Dense(64, activation='relu')(merged_layer)\n",
    "        output = layers.Dense(output_dim, activation='sigmoid')(fuse_layer)\n",
    "\n",
    "        model = keras.Model(inputs=input_layers, outputs=output)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\", tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "\n",
    "\n",
    "    return create_model\n",
    "model_fuse = create_fuse_model(\n",
    "    input_dim=hidden_size, party_nums=2, output_dim=1)\n",
    "model_fuse()\n",
    "base_model_dict = {\n",
    "    alice: model_base_alice,\n",
    "    bob:   model_base_bob\n",
    "}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc87fb7-76ec-4a44-93d9-030a5a71728c",
   "metadata": {},
   "source": [
    "alice方采用embeddingDP加噪方法，bob方采用LabelDP（前面数据划分中是alice获得标签列，所以对此处加噪方式存在疑惑）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0e9334-222b-4175-966c-a5d9de179ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.security.privacy import DPStrategy, GaussianEmbeddingDP, LabelDP\n",
    "\n",
    "# Define DP operations差分隐私\n",
    "train_batch_size = 128\n",
    "gaussian_embedding_dp = GaussianEmbeddingDP(\n",
    "    noise_multiplier=0.5,\n",
    "    l2_norm_clip=1.0,\n",
    "    batch_size=train_batch_size,\n",
    "    num_samples=train_data.values.partition_shape()[alice][0],\n",
    "    is_secure_generator=False,\n",
    ")\n",
    "dp_strategy_alice = DPStrategy(embedding_dp=gaussian_embedding_dp)\n",
    "label_dp = LabelDP(eps=64.0)\n",
    "dp_strategy_bob = DPStrategy(label_dp=label_dp)\n",
    "dp_strategy_dict = {alice: dp_strategy_alice, bob: dp_strategy_bob}\n",
    "dp_spent_step_freq = 10\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=alice,\n",
    "    model_fuse=model_fuse,\n",
    "    dp_strategy_dict=dp_strategy_dict)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eda6b398-f557-4c99-8302-ca245323a4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "sl_model.fit(train_data,\n",
    "             train_label,\n",
    "             validation_data=(test_data,test_label),\n",
    "             epochs=10,\n",
    "             batch_size=train_batch_size,\n",
    "             shuffle=True,\n",
    "             verbose=1,\n",
    "             validation_freq=1,\n",
    "             dp_spent_step_freq=None,)\n",
    "\n",
    "sf.reveal(test_data.partitions[alice].data), sf.reveal(test_label.partitions[alice].data)\n",
    "sf.reveal(train_data.partitions[alice].data), sf.reveal(train_label.partitions[alice].data)\n",
    "\n",
    "history = sl_model.fit(\n",
    "    train_data,\n",
    "    train_label,\n",
    "    validation_data=(test_data, test_label),\n",
    "    epochs=20,\n",
    "    batch_size=train_batch_size,\n",
    "    shuffle=True,\n",
    "    verbose=1,\n",
    "    validation_freq=1,\n",
    "    dp_spent_step_freq=dp_spent_step_freq,\n",
    ")\n",
    "\n",
    "print(history)\n",
    "print(history.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ed7d0-983a-40ee-a6dc-5a413589cd35",
   "metadata": {},
   "source": [
    "画出精确度、损失与AUC图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4894639-8773-4094-9a5d-969193befe59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change of loss during training\n",
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train','Val'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33300e7a-c5e4-499d-92e1-6d606804e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the change of accuracy during training\n",
    "plt.plot(history['train_accuracy'])\n",
    "plt.plot(history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad68cbb-2ead-4120-919d-497bfd98577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the Area Under Curve(AUC) of loss during training\n",
    "plt.plot(history['train_auc_1'])\n",
    "plt.plot(history['val_auc_1'])\n",
    "plt.title('Model Area Under Curve')\n",
    "plt.ylabel('Area Under Curve')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper left')\n",
    "plt.show()\n",
    "global_metric = sl_model.evaluate(test_data, test_label, batch_size=128)\n",
    "print(global_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3bf04-3f50-4b99-a3d3-6371b7e7227c",
   "metadata": {},
   "source": [
    "由实验结果可知，LLDP差分隐私策略在隐语可信计算环境下并不影响原始模型任务性能且有两个训练指标优于内置strategy。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secretflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7029fb0de41c488f0b6618d8e04906432170cb5f9bac89b486d6f69c509a159e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
