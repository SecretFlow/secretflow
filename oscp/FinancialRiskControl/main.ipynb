{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 初始化隐语框架\n",
    "在本次实验中，我们将会包含两个节点：alice 和 bob . 在真实业务场景，他们将会代表两个不同实体，他们之间的原始数据不被允许直接相互传输，但是他们的原始数据将会被一起用以研发一个模型。\n",
    "\n",
    "在下面的代码中，我们建立了一个 SecretFlow Cluster, 基于 alice 和 bob 两个节点，我们还创建了三个device：\n",
    "\n",
    "alice: PYU device, 负责在alice侧的本地计算，计算输入、计算过程和计算结果仅alice可见\n",
    "bob: PYU device, 负责在bob侧的本地计算，计算输入、计算过程和计算结果仅bob可见\n",
    "spu: SPU device, 负责alice和bob之间的密态计算，计算输入和计算结果为密态，由alice和bob各掌握一个分片，计算过程为MPC计算，由alice和bob各自的SPU Runtime一起执行。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address='local')\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 数据集\n",
    "本次实验我们采用的原始数据是来自UCI的Bank Marketing Data Set. 这个数据集汇集了一家葡萄牙银行机构电话营销的结果。\n",
    "\n",
    "我们添加了uid这一列用于接下来隐私求交的实验。\n",
    "\n",
    "我们首先看一下数据集所包含的信息。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "df = pd.read_csv(\n",
    "    '/root/develop/Open_Source/ant-sf/secretflow/oscp/FinancialRiskControl/bank-full.csv',\n",
    "    sep=';',\n",
    ")\n",
    "df['uid'] = df.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_alice = df.iloc[:, np.r_[0:8, -1]].sample(frac=0.9)\n",
    "df_bob = df.iloc[:, 8:].sample(frac=0.9)\n",
    "alice_path = r\"/root/develop/Open_Source/ant-sf/secretflow/oscp/FinancialRiskControl/data/alice_data\"\n",
    "bob_path = r\"/root/develop/Open_Source/ant-sf/secretflow/oscp/FinancialRiskControl/data/bob_data\"\n",
    "df_alice.reset_index(drop=True).to_csv(alice_path, index=False)\n",
    "df_bob.reset_index(drop=True).to_csv(bob_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 样本对齐（隐私求交）\n",
    "显然，第一步我们需要将两边的数据对齐。 隐私求交（Private Set Intersection)是一种密码学方法，可以获取两个集合的交集，而不泄露任何其他信息。 在隐语中，SPU设备支持三种隐私求交算法:\n",
    "\n",
    "ECDH：半诚实模型, 基于公钥密码学，原本适用于小数据集，但是隐语优化后已经能支持10亿量级的数据。\n",
    "KKRT：半诚实模型, 基于布谷鸟哈希（Cuckoo Hashing）以及高效不经意传输扩展（OT Extension），适用于大数据集（比如千万数据集）。\n",
    "BC22PCG：半诚实模型, 基于随机相关函数生成器，适用于大数据集。\n",
    "由于我们这里的数据集较小，我们这里采用的是ECDH方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_psi_path = (\n",
    "    r\"/root/develop/Open_Source/ant-sf/secretflow/oscp/FinancialRiskControl/data/alice_psi_data\"\n",
    ")\n",
    "bob_psi_path = (\n",
    "    r\"/root/develop/Open_Source/ant-sf/secretflow/oscp/FinancialRiskControl/data/bob_psi_data\"\n",
    ")\n",
    "\n",
    "spu.psi_csv(\n",
    "    key=\"uid\",\n",
    "    input_path={alice: alice_path, bob: bob_path},\n",
    "    output_path={alice: alice_psi_path, bob: bob_psi_path},\n",
    "    receiver=\"alice\",\n",
    "    protocol=\"RR22_FAST_PSI_2PC\",\n",
    "    sort=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.data.vertical import read_csv as v_read_csv\n",
    "\n",
    "vdf = v_read_csv(\n",
    "    {alice: alice_path, bob: bob_path},\n",
    "    spu=spu,\n",
    "    keys=\"uid\",\n",
    "    drop_keys=\"uid\",\n",
    "    psi_protocl=\"RR22_FAST_PSI_2PC\",\n",
    ")\n",
    "vdf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 特征预处理\n",
    "一般情况下，我们都需要对用于建模的数据进行预处理，合理的预处理对模型训练效果非常关键。\n",
    "\n",
    "在开始特征预处理之前，我们先使用 stats.table_statistics.table_statistics 来查看一下特征总体情况，我们会在后面专门讨论全表统计模块。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats.table_statistics import table_statistics\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "data_stats = table_statistics(vdf)\n",
    "data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "值替换"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf['education'] = vdf['education'].replace(\n",
    "    {'tertiary': 3, 'secondary': 2, 'primary': 1, 'unknown': np.NaN}\n",
    ")\n",
    "\n",
    "vdf['default'] = vdf['default'].replace({'no': 0, 'yes': 1, 'unknown': np.NaN})\n",
    "\n",
    "vdf['housing'] = vdf['housing'].replace({'no': 0, 'yes': 1, 'unknown': np.NaN})\n",
    "\n",
    "vdf['loan'] = vdf['loan'].replace({'no': 0, 'yes': 1, 'unknown': np.NaN})\n",
    "\n",
    "vdf['month'] = vdf['month'].replace(\n",
    "    {\n",
    "        'jan': 1,\n",
    "        'feb': 2,\n",
    "        'mar': 3,\n",
    "        'apr': 4,\n",
    "        'may': 5,\n",
    "        'jun': 6,\n",
    "        'jul': 7,\n",
    "        'aug': 8,\n",
    "        'sep': 9,\n",
    "        'oct': 10,\n",
    "        'nov': 11,\n",
    "        'dec': 12,\n",
    "    }\n",
    ")\n",
    "\n",
    "vdf['y'] = vdf['y'].replace(\n",
    "    {\n",
    "        'no': 0,\n",
    "        'yes': 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "print(sf.reveal(vdf.partitions[alice].data))\n",
    "print(sf.reveal(vdf.partitions[bob].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "缺失值填充"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vdf[\"education\"] = vdf[\"education\"].fillna(vdf[\"education\"].mode())\n",
    "vdf[\"default\"] = vdf[\"default\"].fillna(vdf[\"default\"].mode())\n",
    "vdf[\"housing\"] = vdf[\"housing\"].fillna(vdf[\"housing\"].mode())\n",
    "vdf[\"loan\"] = vdf[\"loan\"].fillna(vdf[\"loan\"].mode())\n",
    "\n",
    "print(sf.reveal(vdf.partitions[alice].data))\n",
    "print(sf.reveal(vdf.partitions[bob].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### woe分箱\n",
    "woe分箱用于将连续值替换为离散值。\n",
    "将连续型特征离散化的一个好处是可以有效地克服数据中隐藏的缺陷： 使模型结果更加稳定。例如，数据中的极端值是影响模型效果的一个重要因素。极端值导致模型参数过高或过低，或导致模型被虚假现象”迷惑”，把原来不存在的关系作为重要模式来学习。而离散化可以有效地减弱极端值和异常值的影响。\n",
    "变量duration的75%分位数远小于最大值，而且该变量的标准差相对也比较大。因此需要对变量duration进行离散化。\n",
    "woe分桶需要利用alice和bob两边的数据，因此相关的计算需要使用SPU device确保原始数据不被泄露。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.preprocessing.binning.vert_woe_binning import VertWoeBinning\n",
    "from secretflow.preprocessing.binning.vert_bin_substitution import VertBinSubstitution\n",
    "\n",
    "binning = VertWoeBinning(spu)\n",
    "bin_rules = binning.binning(\n",
    "    vdf,\n",
    "    binning_method=\"chimerge\",\n",
    "    bin_num=4,\n",
    "    bin_names={alice: [], bob: [\"duration\"]},\n",
    "    label_name=\"y\",\n",
    ")\n",
    "\n",
    "woe_sub = VertBinSubstitution()\n",
    "vdf = woe_sub.substitution(vdf, bin_rules)\n",
    "\n",
    "print(sf.reveal(vdf.partitions[alice].data))\n",
    "print(sf.reveal(vdf.partitions[bob].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot编码\n",
    "one-hot编码适用于将类型编码转化为数值编码。 对于job、marital等特征我们需要one-hot编码。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.preprocessing.encoder import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder()\n",
    "# for vif and correlation only\n",
    "vdf_hat = vdf.drop(columns=[\"job\", \"marital\", \"contact\", \"month\", \"day\", \"poutcome\"])\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['job'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['marital'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['contact'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['month'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['day'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "tranformed_df = encoder.fit_transform(vdf['poutcome'])\n",
    "vdf[tranformed_df.columns] = tranformed_df\n",
    "\n",
    "vdf = vdf.drop(columns=[\"job\", \"marital\", \"contact\", \"month\", \"day\", \"poutcome\"])\n",
    "\n",
    "print(sf.reveal(vdf.partitions[alice].data))\n",
    "print(sf.reveal(vdf.partitions[bob].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 标准化\n",
    "特征之间数值差距太大会使得模型收敛困难，我们一般先对数值进行标准化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.preprocessing import StandardScaler\n",
    "\n",
    "X = vdf.drop(columns=['y'])\n",
    "y = vdf['y']\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "vdf[X.columns] = X\n",
    "print(sf.reveal(vdf.partitions[alice].data))\n",
    "print(sf.reveal(vdf.partitions[bob].data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 全表统计\n",
    "我们提供了类似于 pd.DataFrame.describe 来展示所有特征的基本统计信息。\n",
    "在特征预处理的过程中，你可以不断调用全表统计来关注预处理效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats.table_statistics import table_statistics\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "data_stats = table_statistics(vdf)\n",
    "data_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 相关系数矩阵\n",
    "我们接下来计算特征和特征之间，特征和标签之间的相关系数矩阵。\n",
    "计算相关系数矩阵时，one-hot编码各列无需参与计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats.ss_pearsonr_v import PearsonR\n",
    "\n",
    "pearson_r_calculator = PearsonR(spu)\n",
    "corr_matrix = pearson_r_calculator.pearsonr(vdf_hat)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "corr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VIF指标计算\n",
    "隐语还支持VIF的计算来进行多重共线性检验。\n",
    "计算VIF指标时，one-hot编码各列无需参与计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats.ss_vif_v import VIF\n",
    "\n",
    "vif_calculator = VIF(spu)\n",
    "vif_results = vif_calculator.vif(vdf_hat)\n",
    "print(vdf_hat.columns)\n",
    "print(vif_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 随机分割\n",
    "在训练之前，我们需要将数据分割为训练集和验证集。\n",
    "其中train_x和train_y为训练集的特征和标签。test_x和test_y为训练集的特征和标签。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.data.split import train_test_split\n",
    "\n",
    "random_state = 1234\n",
    "\n",
    "train_vdf, test_vdf = train_test_split(vdf, train_size=0.8, random_state=random_state)\n",
    "\n",
    "train_x = train_vdf.drop(columns=['y'])\n",
    "train_y = train_vdf['y']\n",
    "\n",
    "test_x = test_vdf.drop(columns=['y'])\n",
    "test_y = test_vdf['y']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PSI（人群稳定性分析）\n",
    "样本稳定指数是衡量样本变化所产生的偏移量的一种重要指标，通常用来衡量样本的稳定程度，比如样本在两个月份之间的变化是否稳定。通常变量的PSI值在0.1以下表示变化不太显著，在0.1到0.25之间表示有比较显著的变化，大于0.25表示变量变化比较剧烈，需要特殊关注。\n",
    "接下来以balance为例子，确认两次抽样的样本分布是否接近。\n",
    "根据业务需求，PSI分析也可以在数据分析或者特征预处理的时候进行。\n",
    "PSI分析是一个单方运算，由数据owner的PYU Device执行计算。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_df = table_statistics(train_x['balance'])\n",
    "min_val, max_val = stats_df['min'], stats_df['max']\n",
    "from secretflow.stats import psi_eval\n",
    "from secretflow.stats.core.utils import equal_range\n",
    "import jax.numpy as jnp\n",
    "\n",
    "split_points = equal_range(jnp.array([min_val, max_val]), 3)\n",
    "balance_psi_score = psi_eval(train_x['balance'], test_x['balance'], split_points)\n",
    "\n",
    "sf.reveal(balance_psi_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 逻辑回归模型\n",
    "使用 ml.linear.ss_sgd.SSRegression 可以进行密态逻辑回归模型的训练。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以二分类为例，主要流程如下\n",
    "\n",
    "Step 1: 初始化数据集\n",
    "\n",
    "数据提供方分别将数据集Secret Share进入密态，并在密态下concatenate为X。\n",
    "Y数据持有方将Y Secret Share进入密态.\n",
    "在Secret Sharing下初始化w为设定的初始值。\n",
    "数据集要求 X.rows > X.cols：1、样本数过少模型不收敛；2、Y可能会泄漏。\n",
    "Step 2：采用mini-batch梯度下降，重复执行如下步骤，直至到达目标迭代次数\n",
    "\n",
    "Step 2.1：计算预测值 pred = sigmoid(batch_x * w)。sigmoid可使用泰勒展开、分段函数、根号逆S形函数等近似。 \\\n",
    "Step 2.2：计算err = pred - y\n",
    "Step 2.3：计算梯度 grad = batch_x.transpose() * err\n",
    "Step 2.4：如果使用 L2 penalty，更新梯度 grad = grad + w’ * l2_norm，其中w’的截距项为0\n",
    "Step 2.5：迭代权重 w = w - (grad * learning_rate / batch_size)\n",
    "Step 3：输出模型，此时w处在Secret Sharing状态。根据需要可以将reveal (w)为明文输出或直接保存密态分片。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.linear.ss_sgd import SSRegression\n",
    "\n",
    "lr_model = SSRegression(spu)\n",
    "lr_model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    epochs=3,\n",
    "    learning_rate=0.1,\n",
    "    batch_size=1024,\n",
    "    sig_type='t1',\n",
    "    reg_type='logistic',\n",
    "    penalty='l2',\n",
    "    l2_norm=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SSHE-LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first, init a HEU device that alice is sk_keeper and bob is evaluator\n",
    "heu_config = sf.utils.testing.heu_config(sk_keeper='alice', evaluators=['bob'])\n",
    "heu_x = sf.HEU(heu_config, spu.cluster_def['runtime_config']['field'])\n",
    "\n",
    "# then, init a HEU device that bob is sk_keeper and alice is evaluator\n",
    "heu_config = sf.utils.testing.heu_config(sk_keeper='bob', evaluators=['alice'])\n",
    "heu_y = sf.HEU(heu_config, spu.cluster_def['runtime_config']['field'])\n",
    "\n",
    "# 定义两个sk_keeper\n",
    "\n",
    "from secretflow.ml.linear.hess_sgd import HESSLogisticRegression\n",
    "\n",
    "hess_lr_model = HESSLogisticRegression(spu, heu_x, heu_y)\n",
    "# HESSLogisticRegression(spu, heu_x, heu_y)\n",
    "# spu – SPU SPU device.\n",
    "# heu_x – HEU HEU device without label.\n",
    "# heu_y – HEU HEU device with label.\n",
    "# Here, label belong to bob (heu_y)\n",
    "\n",
    "hess_lr_model.fit(\n",
    "    x=train_x,\n",
    "    y=train_y,\n",
    "    learning_rate=0.1,\n",
    "    epochs=3,\n",
    "    batch_size=1024\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost模型\n",
    "使用 ml.boost.ss_xgb_v.Xgb 可以进行密态XGBoost模型的训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.boost.ss_xgb_v import Xgb\n",
    "\n",
    "xgb = Xgb(spu)\n",
    "params = {\n",
    "    'num_boost_round': 3,\n",
    "    'max_depth': 5,\n",
    "    'sketch_eps': 0.25,\n",
    "    'objective': 'logistic',\n",
    "    'reg_lambda': 0.2,\n",
    "    'subsample': 1,\n",
    "    'colsample_by_tree': 1,\n",
    "    'base_score': 0.5,\n",
    "}\n",
    "xgb_model = xgb.train(params=params, dtrain=train_x, label=train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 模型预测\n",
    "由于在我们的场景下，数据集标签的持有者是bob，因此我们在这里将预测结果reveal给bob.\n",
    "当设置to_pyu，预测结果将会被reveal给该方，否则将仍然保持秘密分享的状态。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_y_hat = lr_model.predict(x=test_x, batch_size=1024, to_pyu=bob)\n",
    "xgb_y_hat = xgb_model.predict(dtrain=test_x, to_pyu=bob)\n",
    "hess_lr_y_hat = hess_lr_model.predict(x=test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 二分类评估\n",
    "隐语中对二分类的评估有集成的支持。\n",
    "BiClassificationEval 将计算 AUC, KS, F1 Score, Lift, K-S, Gain, Precision, Recall 等统计数值， 并提供（基于prediction score的）等频和等距分箱的统计报告和总报告。\n",
    "不同分桶中评估模型的预测的threshold不同。总报告中依赖threshold的统计取的是各个分桶的最佳值。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats.biclassification_eval import BiClassificationEval\n",
    "\n",
    "biclassification_evaluator = BiClassificationEval(\n",
    "    y_true=test_y, y_score=lr_y_hat, bucket_size=20\n",
    ")\n",
    "lr_report = sf.reveal(biclassification_evaluator.get_all_reports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'positive_samples: {lr_report.summary_report.positive_samples}')\n",
    "print(f'negative_samples: {lr_report.summary_report.negative_samples}')\n",
    "print(f'total_samples: {lr_report.summary_report.total_samples}')\n",
    "print(f'auc: {lr_report.summary_report.auc}')\n",
    "print(f'ks: {lr_report.summary_report.ks}')\n",
    "print(f'f1_score: {lr_report.summary_report.f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biclassification_evaluator = BiClassificationEval(\n",
    "    y_true=test_y, y_score=xgb_y_hat, bucket_size=20\n",
    ")\n",
    "xgb_report = sf.reveal(biclassification_evaluator.get_all_reports())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'positive_samples: {xgb_report.summary_report.positive_samples}')\n",
    "print(f'negative_samples: {xgb_report.summary_report.negative_samples}')\n",
    "print(f'total_samples: {xgb_report.summary_report.total_samples}')\n",
    "print(f'auc: {xgb_report.summary_report.auc}')\n",
    "print(f'ks: {xgb_report.summary_report.ks}')\n",
    "print(f'f1_score: {xgb_report.summary_report.f1_score}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "biclassification_evaluator = BiClassificationEval(\n",
    "    y_true=test_y, y_score=hess_lr_y_hat, bucket_size=20\n",
    ")\n",
    "hess_lr_report = sf.reveal(biclassification_evaluator.get_all_reports())\n",
    "\n",
    "print(f'positive_samples: {hess_lr_report.summary_report.positive_samples}')\n",
    "print(f'negative_samples: {hess_lr_report.summary_report.negative_samples}')\n",
    "print(f'total_samples: {hess_lr_report.summary_report.total_samples}')\n",
    "print(f'auc: {hess_lr_report.summary_report.auc}')\n",
    "print(f'ks: {hess_lr_report.summary_report.ks}')\n",
    "print(f'f1_score: {hess_lr_report.summary_report.f1_score}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 预测偏差\n",
    "结果由abs(mean(Acutal) - mean(Prediction))计算获得, 值越小越好。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats import prediction_bias_eval\n",
    "\n",
    "prediction_bias = prediction_bias_eval(\n",
    "    test_y, lr_y_hat, bucket_num=4, absolute=True, bucket_method='equal_width'\n",
    ")\n",
    "\n",
    "sf.reveal(prediction_bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_pva_score = prediction_bias_eval(\n",
    "    test_y, xgb_y_hat, bucket_num=4, absolute=True, bucket_method='equal_width'\n",
    ")\n",
    "\n",
    "sf.reveal(xgb_pva_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### P-Value\n",
    "双方可通过p-value的值来判断参数是否显著，即该自变量是否可以有效预测因变量的变异, 从而判定对应的解释变量是否应包括在模型中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats import SSPValue\n",
    "\n",
    "model = lr_model.save_model()\n",
    "sspv = SSPValue(spu)\n",
    "pvalues = sspv.pvalues(test_x, test_y, model)\n",
    "\n",
    "pvalues"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 评分卡转换\n",
    "严格来说，评分卡转化是对预测结果的后续处理，并不属于模型评估。\n",
    "\n",
    "我们将 y = 1 的概率设为p， odds = p / (1 - p), 评分卡设定的分值刻度可以通过将分值表示为比率对数的线性表达式来定义，即可表示为下式：\n",
    "\n",
    "Score = A - B log(odds)， A 和 B 是可以设定的常数。隐语中提供了评分卡转换功能，详情可以参考API文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.stats import BiClassificationEval, ScoreCard\n",
    "\n",
    "sc = ScoreCard(20, 600, 20)\n",
    "score = sc.transform(xgb_y_hat)\n",
    "\n",
    "sf.reveal(score.partitions[bob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secretflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
