{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46393047-fd37-47b1-8723-33395d61053a",
   "metadata": {},
   "source": [
    "以下代码满足#766任务中结合SLModel实现Yahoo Answers数据集完成Layer-wise算法实现。其中数据集的封装是在datasets.py中通过load_yahoo函数实现。运行该代码需要满足以下前置条件：\n",
    "1. 下载Yahoo Answers数据集至本地。\n",
    "2. 在原有数据集上命名四个属性，分别代表问答类型（标签），问题，问题附加与回答，处理好数据集后保存。\n",
    "user_data = pd.read_csv(path, header=None, encoding=\"utf-8\") \n",
    "user_data.columns = ['type', 'question', 'attention', 'answers'] \n",
    "\n",
    "4. 修改dataset.py中的load_yahoo中的文件绝对路径。\n",
    "5. 将dataset.py置于目录secretflow/utils/simulation下替换原有dataset.py。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08ad819",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2022 Ant Group Co., Ltd.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#      https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License.\n",
    "\n",
    "# Author: Yuanran Song\n",
    "# E-mail: 809127446@qq.com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d366abb8-03db-4241-9c2d-1d18c40ece73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import secretflow as sf\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List\n",
    "import math\n",
    "import numpy as np\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address='local')\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "import pandas as pd\n",
    "from secretflow.utils.simulation.datasets import dataset\n",
    "\n",
    "\n",
    "from secretflow.data.split import train_test_split\n",
    "from secretflow.ml.nn import SLModel\n",
    "# spu = sf.SPU(sf.utils.testing.cluster_def(['alice', 'bob']))\n",
    "from secretflow.utils.simulation.datasets import load_yahoo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5632fc81-e5cb-4cfb-b626-529d0278cb30",
   "metadata": {},
   "source": [
    "yahoo数据集读取与预处理，由于yahoo数据集没有特征名与标签名因此添加了四个属性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88e4e20-a2ae-4f04-bbb7-0351e90c82dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_yahoo (parts={alice: (1, 2), bob: (2, 4)}, axis=1)\n",
    "# Alice holds the label.\n",
    "label = load_yahoo(parts={alice: (0, 1)}, axis=1)\n",
    "# data['age'].partitions[alice].data\n",
    "from secretflow.preprocessing.scaler import MinMaxScaler\n",
    "from secretflow.preprocessing.encoder import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "data['question'] = encoder.fit_transform(data['question'])\n",
    "data['attention'] = encoder.fit_transform(data['attention'])\n",
    "data['answers'] = encoder.fit_transform(data['answers'])\n",
    "label = encoder.fit_transform(label)\n",
    "print(f\"label= {type(label)},\\ndata = {type(data)}\")\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "data = scaler.fit_transform(data)\n",
    "from secretflow.data.split import train_test_split\n",
    "random_state = 1234\n",
    "train_data,test_data = train_test_split(data, train_size=0.8, random_state=random_state)\n",
    "train_label,test_label = train_test_split(label, train_size=0.8, random_state=random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2d3f70a-7746-4297-b455-cdb39dcd424e",
   "metadata": {},
   "source": [
    "创建拆分学习双方模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b6c67cc-c6be-4c87-89b2-c8e5721d21d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_base_model(input_dim, output_dim,  name='base_model'):\n",
    "    # Create model\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        model = keras.Sequential(\n",
    "            [\n",
    "                keras.Input(shape=input_dim),\n",
    "                layers.Dense(100,activation =\"relu\" ),\n",
    "                layers.Dense(output_dim, activation=\"relu\"),\n",
    "            ]\n",
    "        )\n",
    "        # Compile model\n",
    "        model.summary()\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "    return create_model\n",
    "# prepare model\n",
    "hidden_size = 64\n",
    "# get the number of features of each party.\n",
    "# When the input data changes, the network automatically adjusts to the input data\n",
    "alice_input_feature_num = train_data.values.partition_shape()[alice][1]\n",
    "bob_input_feature_num = train_data.values.partition_shape()[bob][1]\n",
    "\n",
    "model_base_alice = create_base_model(alice_input_feature_num, hidden_size)\n",
    "model_base_bob = create_base_model(bob_input_feature_num, hidden_size)\n",
    "model_base_alice()\n",
    "model_base_bob()\n",
    "\n",
    "\n",
    "def create_fuse_model(input_dim, output_dim, party_nums, name='fuse_model'):\n",
    "    def create_model():\n",
    "        from tensorflow import keras\n",
    "        from tensorflow.keras import layers\n",
    "        import tensorflow as tf\n",
    "        # input\n",
    "        input_layers = []\n",
    "        for i in range(party_nums):\n",
    "            input_layers.append(keras.Input(input_dim,))\n",
    "\n",
    "        merged_layer = layers.concatenate(input_layers)\n",
    "        fuse_layer = layers.Dense(64, activation='relu')(merged_layer)\n",
    "        output = layers.Dense(output_dim, activation='sigmoid')(fuse_layer)\n",
    "\n",
    "        model = keras.Model(inputs=input_layers, outputs=output)\n",
    "        model.summary()\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                      optimizer='adam',\n",
    "                      metrics=[\"accuracy\",tf.keras.metrics.AUC()])\n",
    "        return model\n",
    "    return create_model\n",
    "model_fuse = create_fuse_model(\n",
    "    input_dim=hidden_size, party_nums=2, output_dim=1)\n",
    "model_fuse()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a2cffcfd-7320-455d-b55a-5b47e3bb09cd",
   "metadata": {},
   "source": [
    "接下来定义lldp_strategy，我们可以使用其对base_model与fuse_model实现逐层差分隐私加噪。\n",
    "其相较于隐语内置dp_strategy里的embedding_dp（embedding层加噪）与label_dp（标签加噪）相比。使用LLDP策略的全局模型具有更快的收敛速度和更高的预测准确性。这些改进来自于LLDP算法中对隐私预算进行了层次化的分配。\n",
    "实验结果会于代码末尾附上。以下代码给出fuse_model进行加噪的例子，往函数中输入base_model也可实现对本地模型的加噪策略。用户可根据隐私保护需求自由选择。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c40f8c-e69e-40bf-9dae-60583ed7ee6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lldp_strategy(model):\n",
    "    model_data_list = model().get_weights()\n",
    "    print(model_data_list)\n",
    "    delta = math.exp(-3)\n",
    "    epsilon = [80, 80, 40, 40, 30, 30]  ##对三层模型进行加噪\n",
    "    # data_list_l = data[:4]\n",
    "    # data_list_r = data[4:]\n",
    "    for i in range(len(model_data_list)):\n",
    "        sigma = math.sqrt(2 * math.log(1.25 / delta)) / epsilon[i]\n",
    "        # print(\"sigma:\", sigma)\n",
    "        noise = np.random.normal(0, sigma, model_data_list[i].shape)\n",
    "        # add_noise\n",
    "        model_data_list[i] = model_data_list[i] + noise\n",
    "    model().set_weights(model_data_list)\n",
    "    return model\n",
    "model_fuse= create_lldp_strategy(model_fuse)\n",
    "model_fuse()\n",
    "\n",
    "base_model_dict = {\n",
    "    alice: model_base_alice,\n",
    "    bob:   model_base_bob\n",
    "}\n",
    "\n",
    "train_batch_size = 128\n",
    "\n",
    "sl_model = SLModel(\n",
    "    base_model_dict=base_model_dict,\n",
    "    device_y=alice,\n",
    "    model_fuse=model_fuse,)\n",
    "    # dp_strategy_dict=dp_strategy_dict,)\n",
    "\n",
    "sf.reveal(test_data.partitions[alice].data), sf.reveal(test_label.partitions[alice].data)\n",
    "sf.reveal(train_data.partitions[alice].data), sf.reveal(train_label.partitions[alice].data)\n",
    "history =  sl_model.fit(train_data,\n",
    "             train_label,\n",
    "             validation_data=(test_data,test_label),\n",
    "             epochs=10,\n",
    "             batch_size=train_batch_size,\n",
    "             shuffle=True,\n",
    "             verbose=1,\n",
    "             validation_freq=1,)\n",
    "             # dp_spent_step_freq=dp_spent_step_freq,)\n",
    "print(history)\n",
    "print(history.keys())\n",
    "global_metric = sl_model.evaluate(test_data, test_label, batch_size=128)\n",
    "print(global_metric)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "secretflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13 (default, Mar 28 2022, 06:59:08) [MSC v.1916 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "7029fb0de41c488f0b6618d8e04906432170cb5f9bac89b486d6f69c509a159e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
