{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于 PyTorch 的预训练模型在隐语联邦学习环境下的微调\n",
    "## 引言\n",
    "预训练模型加载和精调在机器学习中非常重要。一般来说，从头训练一个非常大的模型，不仅需要大量的算力资源，同时也需要耗费大量的时间。所以在传统的机器学习中，使用预训练模型，然后针对具体的任务做微调和迁移学习非常普遍。同样的，对于联邦学习来说，如果能够加载预训练模型进行微调和迁移学习，不仅能够节省参与方的算力资源，降低参与方的准入门槛，同时也能够加快模型的学习速度。\n",
    "\n",
    "得益于隐语联邦学习模块优异的兼容性，使得其可以直接加载 PyTorch 的一系列[预训练模型](https://pytorch.org/vision/master/models.html)；本教程将基于 PyTorch 的[AlexNet](https://proceedings.neurips.cc/paper_files/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)的微调教程展现如何基于PyTorch的[预训练模型](https://pytorch.org/vision/master/models/alexnet.html)在SecretFlow的框架下进行微调，充分展现SecretFlow的易用性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集\n",
    "### 数据集介绍\n",
    "Flower 数据集介绍：flower 数据集是一个包含了 5 种花卉（雏菊、蒲公英、玫瑰、向日葵、郁金香）共计 4323 张彩色图片的数据集。每种花卉都有多个角度和不同光照下的图片，每张图片的分辨率为 320x240。这个数据集常用于图像分类和机器学习算法的训练与测试。数据集中每个类别的数量分别是：daisy（633），dandelion（898），rose（641），sunflower（699），tulip（852）\n",
    "\n",
    "下载地址: http://download.tensorflow.org/example_images/flower_photos.tgz\n",
    "\n",
    "### 下载数据集并解压"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 02:34:06.037771: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 02:34:06.237306: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-09-25 02:34:06.242086: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2023-09-25 02:34:06.242103: I tensorflow/compiler/xla/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2023-09-25 02:34:07.303117: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 02:34:07.303192: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-09-25 02:34:07.303199: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\n",
      "67588319/67588319 [==============================] - 2s 0us/step\n"
     ]
    }
   ],
   "source": [
    "# The TensorFlow interface is reused to download images , and the output is a folder, as shown in the following figure.\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "\n",
    "_temp_dir = tempfile.mkdtemp()\n",
    "path_to_flower_dataset = tf.keras.utils.get_file(\n",
    "    \"flower_photos\",\n",
    "    \"https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/tf_flowers/flower_photos.tgz\",\n",
    "    untar=True,\n",
    "    cache_dir=_temp_dir,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 环境设置\n",
    "首先我们初始化各个参与方。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The version of SecretFlow: 1.2.0.dev20230918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-09-25 02:34:15,192\tINFO worker.py:1538 -- Started a local Ray instance.\n"
     ]
    }
   ],
   "source": [
    "import secretflow as sf\n",
    "\n",
    "# Check the version of your SecretFlow\n",
    "print('The version of SecretFlow: {}'.format(sf.__version__))\n",
    "\n",
    "# In case you have a running secretflow runtime already.\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob', 'charlie'], address=\"local\", log_to_driver=False)\n",
    "alice, bob, charlie = sf.PYU('alice'), sf.PYU('bob'), sf.PYU('charlie')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义Dataloader\n",
    "我们可以参考[PyTorch下的DataBuilder教程](https://www.secretflow.org.cn/docs/secretflow/latest/zh-Hans/tutorial/CustomDataLoaderTorch)定义我们自己的DataBuilder。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_builder(\n",
    "    batch_size=32,\n",
    "    train_split=0.8,\n",
    "    shuffle=True,\n",
    "    random_seed=1234,\n",
    "):\n",
    "    def dataset_builder(x, stage=\"train\"):\n",
    "        \"\"\" \"\"\"\n",
    "        import math\n",
    "\n",
    "        import numpy as np\n",
    "        from torch.utils.data import DataLoader\n",
    "        from torch.utils.data.sampler import SubsetRandomSampler\n",
    "        from torchvision import datasets, transforms\n",
    "\n",
    "        # Define dataset\n",
    "        flower_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize((180, 180)),\n",
    "                transforms.ToTensor(),\n",
    "            ]\n",
    "        )\n",
    "        flower_dataset = datasets.ImageFolder(x, transform=flower_transform)\n",
    "        dataset_size = len(flower_dataset)\n",
    "        # Define sampler\n",
    "\n",
    "        indices = list(range(dataset_size))\n",
    "        if shuffle:\n",
    "            np.random.seed(random_seed)\n",
    "            np.random.shuffle(indices)\n",
    "        split = int(np.floor(train_split * dataset_size))\n",
    "        train_indices, val_indices = indices[:split], indices[split:]\n",
    "        train_sampler = SubsetRandomSampler(train_indices)\n",
    "        valid_sampler = SubsetRandomSampler(val_indices)\n",
    "\n",
    "        # Define databuilder\n",
    "        train_loader = DataLoader(\n",
    "            flower_dataset, batch_size=batch_size, sampler=train_sampler\n",
    "        )\n",
    "        valid_loader = DataLoader(\n",
    "            flower_dataset, batch_size=batch_size, sampler=valid_sampler\n",
    "        )\n",
    "\n",
    "        # Return\n",
    "        if stage == \"train\":\n",
    "            train_step_per_epoch = math.ceil(split / batch_size)\n",
    "\n",
    "            return train_loader, train_step_per_epoch\n",
    "        elif stage == \"eval\":\n",
    "            eval_step_per_epoch = math.ceil((dataset_size - split) / batch_size)\n",
    "            return valid_loader, eval_step_per_epoch\n",
    "\n",
    "    return dataset_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dataset dict\n",
    "data_builder_dict = {\n",
    "    alice: create_dataset_builder(\n",
    "        batch_size=32,\n",
    "        train_split=0.8,\n",
    "        shuffle=False,\n",
    "        random_seed=1234,\n",
    "    ),\n",
    "    bob: create_dataset_builder(\n",
    "        batch_size=32,\n",
    "        train_split=0.8,\n",
    "        shuffle=False,\n",
    "        random_seed=1234,\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型\n",
    "我们只要参照教程里对模型的定义，在函数里完成我们对模型的定义即可；可以看到代码几乎不需要作任何修改，只需要进行适当的封装。并且得益于隐语优异的封装性，我们可以在定义模型很快进行进行训练，而不是需要自行编写训练和测试函数；相反如果我们自行从头开始写整个神经网络结构的话，我们需要自行参考AlexNet的[源代码](https://pytorch.org/vision/master/_modules/torchvision/models/alexnet.html#alexnet)，将其适配在隐语的`secretflow.ml.nn.utils.BaseModule`;为便于对比，我们分别给出两种实现方式："
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 加载预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/limingbo_oscp/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from secretflow.ml.nn.utils import BaseModule\n",
    "from torchvision.models import alexnet\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class AlexNet(BaseModule):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.finetune_net = alexnet(weights='IMAGENET1K_V1')\n",
    "        self.finetune_net.classifier[6] = nn.Linear(4096, 5)\n",
    "        nn.init.xavier_uniform_(self.finetune_net.classifier[6].weight)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        return self.finetune_net(xb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 自行编写网络结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "class handy_AlexNet(BaseModule):\n",
    "    def __init__(self, num_classes: int = 5, dropout: float = 0.5, **kwargs) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
    "        )\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(256 * 6 * 6, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=dropout),\n",
    "            nn.Linear(4096, 4096),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4096, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.features(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from secretflow.ml.nn import FLModel\n",
    "from secretflow.security.aggregation import SecureAggregator\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy, Precision\n",
    "from secretflow.ml.nn.fl.utils import metric_wrapper, optim_wrapper\n",
    "from secretflow.ml.nn.utils import TorchModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义 FLModel 并且训练\n",
    "\n",
    "### 基于预训练模型定义 Torch 后端的 FLModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.security.aggregation.secure_aggregator._Masker'> with party bob.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "device_list = [alice, bob]\n",
    "aggregator = SecureAggregator(charlie, [alice, bob])\n",
    "\n",
    "data = {\n",
    "    alice: path_to_flower_dataset,\n",
    "    bob: path_to_flower_dataset,\n",
    "}\n",
    "# prepare model\n",
    "num_classes = 5\n",
    "\n",
    "\n",
    "# torch model\n",
    "loss_fn = nn.CrossEntropyLoss\n",
    "optim_fn = optim_wrapper(optim.Adam, lr=1e-3)\n",
    "model_def = TorchModel(\n",
    "    model_fn=AlexNet,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_fn=optim_fn,\n",
    "    metrics=[\n",
    "        metric_wrapper(\n",
    "            Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "        metric_wrapper(\n",
    "            Precision, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model_def,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"torch\",\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于预训练模型的 FLModel 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:FL Train Params: {'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7fa9b824a550>, 'x': {PYURuntime(alice): '/tmp/tmpkvc4vamk/datasets/flower_photos', PYURuntime(bob): '/tmp/tmpkvc4vamk/datasets/flower_photos'}, 'y': None, 'batch_size': 32, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/tmp/tmpkvc4vamk/datasets/flower_photos', PYURuntime(bob): '/tmp/tmpkvc4vamk/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7fb8186891f0>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7fb81869e280>}, 'wait_steps': 100}\n",
      "100%|██████████| 30/30 [02:21<00:00,  4.82s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "2023-09-25 02:37:04.160466: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-09-25 02:37:05.621964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13757 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:3b:00.0, compute capability: 7.5\n",
      "2023-09-25 02:37:05.624320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13757 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:3c:00.0, compute capability: 7.5\n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:42<00:00,  5.43s/it, epoch: 1/5 -  multiclassaccuracy:0.28333333134651184  multiclassprecision:0.28333333134651184  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:12<00:00,  4.82s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:28<00:00,  4.95s/it, epoch: 2/5 -  multiclassaccuracy:0.3020833432674408  multiclassprecision:0.3020833432674408  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:12<00:00,  4.84s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:28<00:00,  4.96s/it, epoch: 3/5 -  multiclassaccuracy:0.29479166865348816  multiclassprecision:0.29479166865348816  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:24<00:00,  5.40s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:40<00:00,  5.35s/it, epoch: 4/5 -  multiclassaccuracy:0.3020833432674408  multiclassprecision:0.3020833432674408  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:44<00:00,  5.34s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:59<00:00,  6.00s/it, epoch: 5/5 -  multiclassaccuracy:0.296875  multiclassprecision:0.296875  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n"
     ]
    }
   ],
   "source": [
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于自编写网络定义 Torch 后端的 FLModel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.fl.backend.torch.strategy.fed_avg_w.PYUFedAvgW'> with party bob.\n"
     ]
    }
   ],
   "source": [
    "model_def = TorchModel(\n",
    "    model_fn=handy_AlexNet,\n",
    "    loss_fn=loss_fn,\n",
    "    optim_fn=optim_fn,\n",
    "    metrics=[\n",
    "        metric_wrapper(\n",
    "            Accuracy, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "        metric_wrapper(\n",
    "            Precision, task=\"multiclass\", num_classes=num_classes, average='micro'\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "fed_model = FLModel(\n",
    "    device_list=device_list,\n",
    "    model=model_def,\n",
    "    aggregator=aggregator,\n",
    "    backend=\"torch\",\n",
    "    strategy=\"fed_avg_w\",\n",
    "    random_seed=1234,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基于自编写网络模型的 FLModel 开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:FL Train Params: {'self': <secretflow.ml.nn.fl.fl_model.FLModel object at 0x7fa9b81fcca0>, 'x': {PYURuntime(alice): '/tmp/tmpkvc4vamk/datasets/flower_photos', PYURuntime(bob): '/tmp/tmpkvc4vamk/datasets/flower_photos'}, 'y': None, 'batch_size': 32, 'batch_sampling_rate': None, 'epochs': 5, 'verbose': 1, 'callbacks': None, 'validation_data': {PYURuntime(alice): '/tmp/tmpkvc4vamk/datasets/flower_photos', PYURuntime(bob): '/tmp/tmpkvc4vamk/datasets/flower_photos'}, 'shuffle': False, 'class_weight': None, 'sample_weight': None, 'validation_freq': 1, 'aggregate_freq': 2, 'label_decoder': None, 'max_batch_size': 20000, 'prefetch_buffer_size': None, 'sampler_method': 'batch', 'random_seed': 1234, 'dp_spent_step_freq': 1, 'audit_log_dir': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7fb8186891f0>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7fb81869e280>}, 'wait_steps': 100}\n",
      "100%|██████████| 30/30 [02:24<00:00,  5.37s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:42<00:00,  5.41s/it, epoch: 1/5 -  multiclassaccuracy:0.2979166805744171  multiclassprecision:0.2979166805744171  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:19<00:00,  5.26s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:36<00:00,  5.21s/it, epoch: 2/5 -  multiclassaccuracy:0.39375001192092896  multiclassprecision:0.39375001192092896  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:19<00:00,  5.57s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:35<00:00,  5.18s/it, epoch: 3/5 -  multiclassaccuracy:0.4010416567325592  multiclassprecision:0.4010416567325592  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:21<00:00,  5.06s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:36<00:00,  5.21s/it, epoch: 4/5 -  multiclassaccuracy:0.47083333134651184  multiclassprecision:0.47083333134651184  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n",
      "100%|██████████| 30/30 [02:21<00:00,  5.15s/it]WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "WARNING:root:Please pay attention to local metrics, global only do naive aggregation \n",
      "100%|██████████| 30/30 [02:38<00:00,  5.30s/it, epoch: 5/5 -  multiclassaccuracy:0.47083333134651184  multiclassprecision:0.47083333134651184  val_multiclassaccuracy:0.0  val_multiclassprecision:0.0 ]\n"
     ]
    }
   ],
   "source": [
    "history = fed_model.fit(\n",
    "    data,\n",
    "    None,\n",
    "    validation_data=data,\n",
    "    epochs=5,\n",
    "    batch_size=32,\n",
    "    aggregate_freq=2,\n",
    "    sampler_method=\"batch\",\n",
    "    random_seed=1234,\n",
    "    dp_spent_step_freq=1,\n",
    "    dataset_builder=data_builder_dict,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 小结\n",
    "隐语能够无缝地兼容基于 PyTorch 预训练模型，我们可以不需要自己再重新写出复杂网络的模型结构，这对于大型网络结构可以起到省时省力的效果。并且通过加载预训练模型的权重，理论上可以让我们的模型性能更优秀。\n",
    "\n",
    "本篇教程，我们以 AlexNet 为例介绍了如何在隐语的联邦学习模式下基于直接加载 PyTorch 的[预训练模型](https://pytorch.org/vision/stable/models.html)，通过直接加载预训练模型，我们能够获得：\n",
    "- 不需要再次编写复杂模型的结构代码\n",
    "- 基于预训练模型进行微调和迁移学习\n",
    "- 使用预训练权重模型能够使得联邦模型获得更好的性能"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "limingbo_oscp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
