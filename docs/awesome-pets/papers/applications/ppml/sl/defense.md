## Detection and Defenses against Attacks on Split Learning

- [ExPLoit: Extracting Private Labels in Split Learning](https://arxiv.org/pdf/2112.01299.pdf)

- [Shredder: Learning Noise Distributions to Protect Inference Privacy](https://dl.acm.org/doi/10.1145/3373376.3378522)

- [Not Just Privacy: Improving Performance of Private Deep Learning in Mobile Cloud](https://dl.acm.org/doi/10.1145/3219819.3220106)

- [Certified Robustness to Adversarial Examples with Differential Privacy](https://arxiv.org/pdf/1802.03471.pdf)

- [NoPeek: Information leakage reduction to share activations in distributed deep learning](https://arxiv.org/pdf/2008.09161.pdf)

- [NoPeek-Infer: Preventing face reconstruction attacks in distributed inference after on-premise training](https://ieeexplore.ieee.org/document/9667085)

- [Reducing leakage in distributed deep learning for sensitive health data](https://www.media.mit.edu/publications/reducing-leakage-in-distributed-deep-learning-for-sensitive-health-data-accepted-to-iclr-2019-workshop-on-ai-for-social-good-2019/)

- [Label Inference Attacks Against Vertical Federated Learning](https://www.usenix.org/conference/usenixsecurity22/presentation/fu-chong)

- [Batch Label Inference and Replacement Attacks in Black-Boxed Vertical Federated Learning](https://arxiv.org/pdf/2112.05409.pdf)

- [Can We Use Split Learning on 1D CNN Models for Privacy Preserving Training?](https://arxiv.org/pdf/2003.12365.pdf)

- [Practical defences against model inversion attacks for split neural networks](https://arxiv.org/pdf/2104.05743.pdf)

- [Privacy Adversarial Network: Representation Learning for Mobile Data Privacy](https://arxiv.org/pdf/2006.06535.pdf)

- [Adversarial Learning of Privacy-Preserving and Task-Oriented Representations](https://arxiv.org/pdf/1911.10143.pdf)

- [DeepObfuscator: Obfuscating Intermediate Representations with Privacy-Preserving Adversarial Learning on Smartphones](https://arxiv.org/pdf/1909.04126.pdf)

- [Privacy-Preserving Image Template Sharing Using Contrastive Learning](https://www.mdpi.com/1099-4300/24/5/643)

- [ResSFL: A Resistance Transfer Framework for Defending Model Inversion Attack in Split Federated Learning](https://arxiv.org/pdf/2205.04007.pdf)

- [Attacking and Protecting Data Privacy in Edge-Cloud Collaborative Inference Systems](https://ieeexplore.ieee.org/document/9187880)

- [Improving Robustness to Model Inversion Attacks via Mutual Information Regularization](https://arxiv.org/pdf/2009.05241.pdf)

- [MixCon: Adjusting the Separability of Data Representations for Harder Data Recovery](https://arxiv.org/pdf/2010.11463.pdf)

- [SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split Learning](https://arxiv.org/pdf/2108.09052.pdf)

- [Differentially Private CutMix for Split Learning with Vision Transformer](https://arxiv.org/pdf/2210.15986.pdf)

- [DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for deep neural networks](https://arxiv.org/pdf/2012.11025.pdf)

- [Unsupervised Information Obfuscation for Split Inference of Neural Networks](https://arxiv.org/pdf/2104.11413.pdf)