## Backdoor related works in horizontal Federated Learning

An Overview of Federated Learning Backdoor Related Attacks and Defensive Researchs. Updated on 2024-10-01

### Attack

- [How To Backdoor Federated Learning](https://arxiv.org/pdf/1807.00459.pdf)

- [A Little Is Enough: Circumventing Defenses For Distributed Learning](https://proceedings.neurips.cc/paper_files/paper/2019/hash/ec1c59141046cd1866bbbcdfb6ae31d4-Abstract.html)

- [Can You Really Backdoor Federated Learning?](https://arxiv.org/abs/1911.07963)

- [Local Model Poisoning Attacks to Byzantine-Robust Federated Learning](https://www.usenix.org/conference/usenixsecurity20/presentation/fang)

- [Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for FL](https://par.nsf.gov/servlets/purl/10286354)

- [Attack of the Tails: Yes, You Really Can Backdoor Federated Learning](https://papers.nips.cc/paper/2020/file/b8ffa41d4e492f0fad2f13e29e1762eb-Paper.pdf)

- [DBA: Distributed Backdoor Attacks against Federated Learning](https://openreview.net/pdf?id=rkgyS0VFvr)

- [CRFL: Certifiably Robust Federated Learning against Backdoor Attacks. ICML 2021.](https://arxiv.org/pdf/2106.08283.pdf)

- [MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients](https://openaccess.thecvf.com/content/CVPR2022W/FedVision/html/Cao_MPAF_Model_Poisoning_Attacks_to_Federated_Learning_Based_on_Fake_CVPRW_2022_paper.html)

- [3dfed: Adaptive and extensible framework for covert backdoor attack in federated learning](https://ieeexplore.ieee.org/document/10179401)

### Defense

- [Machine Learning with Adversaries: Byzantine Tolerant Gradient Descent](https://proceedings.neurips.cc/paper/2017/hash/f4b9ec30ad9f68f89b29639786cb62ef-Abstract.html)

- [Byzantine-Robust Distributed Learning: Towards Optimal Statistical Rates](https://proceedings.mlr.press/v80/yin18a)

- [The Hidden Vulnerability of Distributed Learning in Byzantium](https://proceedings.mlr.press/v80/mhamdi18a.html)

- [FLTrust: Byzantine-robust Federated Learning via Trust Bootstrapping](https://par.nsf.gov/servlets/purl/10248837)

- [FLDetector: Defending Federated Learning Against Model Poisoning Attacks via Detecting Malicious Clients](https://dl.acm.org/doi/abs/10.1145/3534678.3539231)

- [FLAME: Taming Backdoors in Federated Learning](https://www.usenix.org/conference/usenixsecurity22/fall-accepted-papers)

- [Manipulating the Byzantine: Optimizing Model Poisoning Attacks and Defenses for FL](https://par.nsf.gov/servlets/purl/10286354)

- [Byzantine-robust Federated Learning through Collaborative Malicious Gradient Filtering](https://www.computer.org/csdl/proceedings-article/icdcs/2022/717700b223/1Hrj5rNmE6I)

- [DeepSight: Mitigating Backdoor Attacks in Federated Learning Through Deep Model Inspection](https://www.ndss-symposium.org/wp-content/uploads/2022-156-paper.pdf)

- [FreqFed: A Frequency Analysis-Based Approach for Mitigating Poisoning Attacks in Federated Learning](https://arxiv.org/abs/2312.04432)


