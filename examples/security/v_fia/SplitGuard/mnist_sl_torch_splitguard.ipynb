{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split Learning and SplitGuard detection proposed in paper <SplitGuard: Detecting and Mitigating Training-Hijacking Attacks in Split Learning>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization and model defination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-09 17:40:29,766\tINFO worker.py:1538 -- Started a local Ray instance.\n",
      "2023-10-09 17:40:54.248169: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-09 17:40:54.262854: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-10-09 17:40:54.262894: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='2'\n",
    "import secretflow as sf\n",
    "import matplotlib.pyplot as plt\n",
    "sf.shutdown()\n",
    "sf.init(['alice', 'bob'], address='local',num_cpus=5)\n",
    "alice, bob = sf.PYU('alice'), sf.PYU('bob')\n",
    "partys=[alice,bob]\n",
    "import torch\n",
    "from torch import nn as nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from secretflow.ml.nn.utils import BaseModule\n",
    "class ConvNetBase(BaseModule):\n",
    "    \"\"\"Small ConvNet basenet for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNetBase, self).__init__()\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=1,\n",
    "                out_channels=3,\n",
    "                kernel_size=3,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=3),\n",
    "        )\n",
    "\n",
    "        # fully connected layer, output 10 classes\n",
    "        self.out = nn.Linear(192, 64)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output\n",
    "\n",
    "    def output_num(self):\n",
    "        return 1\n",
    "\n",
    "\n",
    "class ConvNetFuse(BaseModule):\n",
    "    \"\"\"Small ConvNet basenet for MNIST.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        super(ConvNetFuse, self).__init__()\n",
    "        self.fc1 = nn.Linear(64 * 2, 100)\n",
    "        self.fc2 = nn.Linear(100, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.cat(x, dim=1)\n",
    "        x = x.view(-1, 128)\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use label replace to compute the SG score(replace 7 batches out of 79 batches) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import numpy as np\n",
    "from torch import nn, optim\n",
    "from torchmetrics import Accuracy, Precision, AUROC\n",
    "from secretflow.device import reveal\n",
    "from slmodelsg import SLModel_SG\n",
    "from secretflow.ml.nn.fl.utils import metric_wrapper, optim_wrapper\n",
    "from secretflow.ml.nn.utils import TorchModel\n",
    "from secretflow.security.privacy import DPStrategy\n",
    "from secretflow.security.privacy.mechanism.torch import GaussianEmbeddingDP\n",
    "from secretflow.security.privacy.mechanism.label_dp import LabelDP\n",
    "from secretflow.utils.compressor import TopkSparse\n",
    "_temp_dir = tempfile.mkdtemp()\n",
    "NUM_CLASSES = 10\n",
    "INPUT_SHAPE = (28, 28, 1)\n",
    "from secretflow.utils.simulation.data.ndarray import create_ndarray\n",
    "from secretflow.data.ndarray import FedNdarray, PartitionWay\n",
    "from secretflow.device.device.pyu import PYU\n",
    "from typing import Dict, List, Tuple, Union\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from secretflow.utils.simulation.datasets import get_dataset\n",
    "\n",
    "_Dataset = namedtuple('_Dataset', ['filename', 'url', 'sha256'])\n",
    "\n",
    "_DATASETS = {\n",
    "    'mnist': _Dataset(\n",
    "        'mnist.npz',\n",
    "        'https://secretflow-data.oss-accelerate.aliyuncs.com/datasets/mnist/mnist.npz',\n",
    "        '731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1',\n",
    "    )}\n",
    "\n",
    "def load_mnist(\n",
    "    parts: Union[List[PYU], Dict[PYU, Union[float, Tuple]]],\n",
    "    normalized_x: bool = True,\n",
    "    categorical_y: bool = False,\n",
    "    is_torch: bool = False,\n",
    ") -> Tuple[Tuple[FedNdarray, FedNdarray], Tuple[FedNdarray, FedNdarray]]:\n",
    "    filepath = get_dataset(_DATASETS['mnist'])\n",
    "    with np.load(filepath) as f:\n",
    "        x_train, y_train = f['x_train'], f['y_train']\n",
    "        x_test, y_test = f['x_test'], f['y_test']\n",
    "    # Set fake batches as paper.\n",
    "    for i in range(8):\n",
    "        for index in range(128*(i*10+1),128*(i*10+2)):\n",
    "            y_test[index]=(y_test[index]+ random.randint(1,8)) % 10\n",
    "    if normalized_x:\n",
    "        x_train, x_test = x_train / 255, x_test / 255\n",
    "\n",
    "    if categorical_y:\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "        encoder = OneHotEncoder(sparse=False)\n",
    "        y_train = encoder.fit_transform(y_train.reshape(-1, 1))\n",
    "        y_test = encoder.fit_transform(y_test.reshape(-1, 1))\n",
    "    return (\n",
    "        (\n",
    "            create_ndarray(x_train, parts=parts, axis=0, is_torch=is_torch),\n",
    "            create_ndarray(y_train, parts=parts, axis=0),\n",
    "        ),\n",
    "        (\n",
    "            create_ndarray(x_test, parts=parts, axis=0, is_torch=is_torch),\n",
    "            create_ndarray(y_test, parts=parts, axis=0),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def create_dataset_builder(\n",
    "    batch_size=32,\n",
    "):\n",
    "    def dataset_builder(x):\n",
    "        import pandas as pd\n",
    "        import torch\n",
    "        import torch.utils.data as torch_data\n",
    "\n",
    "        x = [t.values if isinstance(t, pd.DataFrame) else t for t in x]\n",
    "        x_copy = [torch.tensor(t.copy()) for t in x]\n",
    "\n",
    "        data_set = torch_data.TensorDataset(*x_copy)\n",
    "        dataloader = torch_data.DataLoader(\n",
    "            dataset=data_set,\n",
    "            batch_size=batch_size,\n",
    "        )\n",
    "        return dataloader\n",
    "\n",
    "    return dataset_builder\n",
    "\n",
    "\n",
    "def torch_model_with_mnist(\n",
    "    devices,\n",
    "    base_model_dict,\n",
    "    device_y,\n",
    "    model_fuse,\n",
    "    data,\n",
    "    label,\n",
    "    strategy='split_nn',\n",
    "    backend='torch',\n",
    "    **kwargs\n",
    "):\n",
    "    # kwargs parsing\n",
    "    dp_strategy_dict = kwargs.get('dp_strategy_dict', None)\n",
    "    compressor = kwargs.get('compressor', None)\n",
    "    dataset_builder = kwargs.get('dataset_builder', None)\n",
    "\n",
    "    base_local_steps = kwargs.get('base_local_steps', 1)\n",
    "    fuse_local_steps = kwargs.get('fuse_local_steps', 1)\n",
    "    bound_param = kwargs.get('bound_param', 0.0)\n",
    "\n",
    "    loss_thres = kwargs.get('loss_thres', 0.01)\n",
    "    split_steps = kwargs.get('split_steps', 1)\n",
    "    max_fuse_local_steps = kwargs.get('max_fuse_local_steps', 10)\n",
    "\n",
    "    party_shape = data.partition_shape()\n",
    "    alice_length = party_shape[devices[0]][0]\n",
    "    \n",
    "    # Define model class using modified class SLModel_SG \n",
    "    sl_model = SLModel_SG(\n",
    "        base_model_dict=base_model_dict,\n",
    "        device_y=device_y,\n",
    "        model_fuse=model_fuse,\n",
    "        dp_strategy_dict=dp_strategy_dict,\n",
    "        compressor=compressor,\n",
    "        simulation=True,\n",
    "        random_seed=1234,\n",
    "        backend=backend,\n",
    "        strategy=strategy,\n",
    "        base_local_steps=base_local_steps,\n",
    "        fuse_local_steps=fuse_local_steps,\n",
    "        bound_param=bound_param,\n",
    "        loss_thres=loss_thres,\n",
    "        split_steps=split_steps,\n",
    "        max_fuse_local_steps=max_fuse_local_steps,\n",
    "    )\n",
    "    # The fit() function is modified.\n",
    "    history = sl_model.fit(\n",
    "        data,\n",
    "        label,\n",
    "        validation_data=(data, label),\n",
    "        epochs=2,\n",
    "        batch_size=128,\n",
    "        shuffle=False,\n",
    "        random_seed=1234,\n",
    "        dataset_builder=dataset_builder,\n",
    "    )\n",
    "    global_metric = sl_model.evaluate(\n",
    "        data,\n",
    "        label,\n",
    "        batch_size=128,\n",
    "        random_seed=1234,\n",
    "        dataset_builder=dataset_builder,\n",
    "    )\n",
    "\n",
    "    # test history\n",
    "    print(global_metric)\n",
    "    print(history)\n",
    "    assert math.isclose(\n",
    "        global_metric['MulticlassAccuracy'],\n",
    "        history['val_MulticlassAccuracy'][-1],\n",
    "        rel_tol=0.01,\n",
    "    )\n",
    "\n",
    "    # assert global_metric['MulticlassAccuracy'] > 0.8\n",
    "    result = sl_model.predict(data, batch_size=128, verbose=1)\n",
    "    reveal_result = []\n",
    "    for rt in result:\n",
    "        reveal_result.extend(reveal(rt))\n",
    "    assert len(reveal_result) == alice_length\n",
    "    base_model_path = os.path.join(_temp_dir, \"base_model\")\n",
    "    fuse_model_path = os.path.join(_temp_dir, \"fuse_model\")\n",
    "    sl_model.save_model(\n",
    "        base_model_path=base_model_path,\n",
    "        fuse_model_path=fuse_model_path,\n",
    "        is_test=True,\n",
    "    )\n",
    "    sl_model_load = SLModel_SG(\n",
    "        base_model_dict=base_model_dict,\n",
    "        device_y=device_y,\n",
    "        model_fuse=model_fuse,\n",
    "        dp_strategy_dict=dp_strategy_dict,\n",
    "        compressor=compressor,\n",
    "        simulation=True,\n",
    "        random_seed=1234,\n",
    "        backend=backend,\n",
    "        strategy=strategy,\n",
    "        base_local_steps=base_local_steps,\n",
    "        fuse_local_steps=fuse_local_steps,\n",
    "        bound_param=bound_param,\n",
    "    )\n",
    "    sl_model_load.load_model(\n",
    "        base_model_path=base_model_path,\n",
    "        fuse_model_path=fuse_model_path,\n",
    "        is_test=True,\n",
    "    )\n",
    "    reload_metric = sl_model_load.evaluate(\n",
    "        data,\n",
    "        label,\n",
    "        batch_size=128,\n",
    "        random_seed=1234,\n",
    "        dataset_builder=dataset_builder,\n",
    "    )\n",
    "    assert math.isclose(\n",
    "        global_metric['MulticlassAccuracy'],\n",
    "        reload_metric['MulticlassAccuracy'],\n",
    "        rel_tol=0.01,\n",
    "    )\n",
    "    # Visualize results\n",
    "    sl_model.plot_sgscore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_torch_model(devices):\n",
    "    alice = devices[0]\n",
    "    bob = devices[1]\n",
    "    num_samples = 10000\n",
    "    (_, _), (mnist_data, mnist_label) = load_mnist(\n",
    "        parts={\n",
    "            alice: (0, num_samples),\n",
    "            bob: (0, num_samples),\n",
    "        },\n",
    "        normalized_x=True,\n",
    "        categorical_y=True,\n",
    "        is_torch=True,\n",
    "    )\n",
    "    mnist_data = mnist_data.astype(np.float32)\n",
    "    mnist_label = mnist_label.astype(np.float32)\n",
    "    loss_fn = nn.CrossEntropyLoss\n",
    "    optim_fn = optim_wrapper(optim.Adam, lr=1e-2)\n",
    "    base_model = TorchModel(\n",
    "        model_fn=ConvNetBase,\n",
    "        loss_fn=loss_fn,\n",
    "        optim_fn=optim_fn,\n",
    "        metrics=[\n",
    "            metric_wrapper(\n",
    "                Accuracy, task=\"multiclass\", num_classes=10, average='micro'\n",
    "            ),\n",
    "            metric_wrapper(\n",
    "                Precision, task=\"multiclass\", num_classes=10, average='micro'\n",
    "            ),\n",
    "            metric_wrapper(AUROC, task=\"multiclass\", num_classes=10),\n",
    "        ],\n",
    "    )\n",
    "\n",
    "    fuse_model = TorchModel(\n",
    "        model_fn=ConvNetFuse,\n",
    "        loss_fn=loss_fn,\n",
    "        optim_fn=optim_fn,\n",
    "        metrics=[\n",
    "            metric_wrapper(\n",
    "                Accuracy, task=\"multiclass\", num_classes=10, average='micro'\n",
    "            ),\n",
    "            metric_wrapper(\n",
    "                Precision, task=\"multiclass\", num_classes=10, average='micro'\n",
    "            ),\n",
    "            metric_wrapper(AUROC, task=\"multiclass\", num_classes=10),\n",
    "        ],\n",
    "    )\n",
    "    base_model_dict = {\n",
    "        alice: base_model,\n",
    "        bob: base_model,\n",
    "    }\n",
    "    # Define DP operations\n",
    "    gaussian_embedding_dp = GaussianEmbeddingDP(\n",
    "        noise_multiplier=0.5,\n",
    "        l2_norm_clip=1.0,\n",
    "        batch_size=128,\n",
    "        num_samples=num_samples,\n",
    "        is_secure_generator=False,\n",
    "    )\n",
    "    dp_strategy_alice = DPStrategy(embedding_dp=gaussian_embedding_dp)\n",
    "    label_dp = LabelDP(eps=64.0)\n",
    "    dp_strategy_bob = DPStrategy(label_dp=label_dp)\n",
    "    dp_strategy_dict = {\n",
    "        alice: dp_strategy_alice,\n",
    "        bob: dp_strategy_bob,\n",
    "    }\n",
    "\n",
    "    # test dataset builder\n",
    "    print(\"test Dataset builder\")\n",
    "    dataset_buidler_dict = {\n",
    "        alice: create_dataset_builder(\n",
    "            batch_size=128,\n",
    "        ),\n",
    "        bob: create_dataset_builder(\n",
    "            batch_size=128,\n",
    "        ),\n",
    "    }\n",
    "    torch_model_with_mnist(\n",
    "        devices=devices,\n",
    "        base_model_dict=base_model_dict,\n",
    "        device_y=bob,\n",
    "        model_fuse=fuse_model,\n",
    "        data=mnist_data,\n",
    "        label=mnist_label,\n",
    "        strategy='split_nn',\n",
    "        backend=\"torch\",\n",
    "        dataset_builder=dataset_buidler_dict,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party alice.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test Dataset builder\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party bob.\n",
      "INFO:root:SL Train Params: {'x': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba760>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba790>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'y': FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adbaaf0>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba970>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), 'batch_size': 128, 'epochs': 2, 'verbose': 1, 'callbacks': None, 'validation_data': (FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba760>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba790>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>), FedNdarray(partitions={PYURuntime(alice): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adbaaf0>, PYURuntime(bob): <secretflow.device.device.pyu.PYUObject object at 0x7fe72adba970>}, partition_way=<PartitionWay.HORIZONTAL: 'horizontal'>)), 'shuffle': False, 'sample_weight': None, 'validation_freq': 1, 'dp_spent_step_freq': None, 'dataset_builder': {PYURuntime(alice): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe72adc5310>, PYURuntime(bob): <function create_dataset_builder.<locals>.dataset_builder at 0x7fe72adc53a0>}, 'audit_log_params': {}, 'random_seed': 1234, 'audit_log_dir': None, 'self': <slmodelsg.SLModel_SG object at 0x7fe7415b65e0>}\n",
      "\u001b[2m\u001b[36m(pid=51206)\u001b[0m 2023-10-09 17:41:10.403562: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=51206)\u001b[0m 2023-10-09 17:41:10.403666: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=51206)\u001b[0m 2023-10-09 17:41:10.403683: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=51208)\u001b[0m 2023-10-09 17:41:10.394667: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=51208)\u001b[0m 2023-10-09 17:41:10.394802: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=51208)\u001b[0m 2023-10-09 17:41:10.394819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m 2023-10-09 17:41:16.249079: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m 2023-10-09 17:41:16.249204: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m 2023-10-09 17:41:16.249222: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "INFO:jax._src.xla_bridge:Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "\u001b[2m\u001b[36m(_run pid=50425)\u001b[0m WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "100%|██████████| 79/79 [00:13<00:00, 11.19it/s]\u001b[2m\u001b[36m(PYUSLTorchModel pid=51208)\u001b[0m /home/zhd/anaconda3/envs/sf-new/lib/python3.8/site-packages/secretflow/ml/nn/sl/backend/torch/sl_base.py:631: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "\u001b[2m\u001b[36m(PYUSLTorchModel pid=51208)\u001b[0m   torch.as_tensor(e)\n",
      "100%|██████████| 79/79 [00:15<00:00,  5.23it/s, epoch: 1/2 -  train_loss:0.5522145628929138  train_MulticlassAccuracy:0.6901000142097473  train_MulticlassPrecision:0.6901000142097473  train_MulticlassAUROC:0.9080532193183899  val_val_loss:0.45470625162124634  val_MulticlassAccuracy:0.7785000205039978  val_MulticlassPrecision:0.7785000205039978  val_MulticlassAUROC:0.9416080713272095 ]\n",
      "  0%|          | 0/79 [00:00<?, ?it/s]\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m 2023-10-09 17:41:30.112255: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m 2023-10-09 17:41:30.112379: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m 2023-10-09 17:41:30.112396: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "  3%|▎         | 2/79 [00:01<01:14,  1.04it/s]\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'cuda': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'rocm': module 'jaxlib.xla_extension' has no attribute 'GpuAllocatorConfig'\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'tpu': INVALID_ARGUMENT: TpuPlatform is not available.\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m INFO:jax._src.xla_bridge:Unable to initialize backend 'plugin': xla_extension has no attributes named get_plugin_device_client. Compile TensorFlow with //tensorflow/compiler/xla/python:enable_plugin_device set to true (defaults to false) to enable this.\n",
      "\u001b[2m\u001b[36m(_run pid=50423)\u001b[0m WARNING:jax._src.xla_bridge:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)\n",
      "100%|██████████| 79/79 [00:09<00:00,  8.32it/s, epoch: 2/2 -  train_loss:0.43498170375823975  train_MulticlassAccuracy:0.8080000281333923  train_MulticlassPrecision:0.8080000281333923  train_MulticlassAUROC:0.9331091046333313  val_val_loss:0.3850078284740448  val_MulticlassAccuracy:0.8077999949455261  val_MulticlassPrecision:0.8077999949455261  val_MulticlassAUROC:0.9485939145088196 ]\n",
      "Evaluate Processing:: 100%|██████████| 79/79 [00:01<00:00, 53.23it/s, val_loss:0.3850078284740448 MulticlassAccuracy:0.8077999949455261 MulticlassPrecision:0.8077999949455261 MulticlassAUROC:0.9485939145088196]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'val_loss': array(0.38500783, dtype=float32), 'MulticlassAccuracy': tensor(0.8078), 'MulticlassPrecision': tensor(0.8078), 'MulticlassAUROC': tensor(0.9486)}\n",
      "{'train_loss': [array(0.55221456, dtype=float32), array(0.4349817, dtype=float32)], 'train_MulticlassAccuracy': [tensor(0.6901), tensor(0.8080)], 'train_MulticlassPrecision': [tensor(0.6901), tensor(0.8080)], 'train_MulticlassAUROC': [tensor(0.9081), tensor(0.9331)], 'val_val_loss': [array(0.45470625, dtype=float32), array(0.38500783, dtype=float32)], 'val_MulticlassAccuracy': [tensor(0.7785), tensor(0.8078)], 'val_MulticlassPrecision': [tensor(0.7785), tensor(0.8078)], 'val_MulticlassAUROC': [tensor(0.9416), tensor(0.9486)]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predict Processing:: 100%|██████████| 79/79 [00:00<00:00, 149.14it/s]\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party alice.\n",
      "INFO:root:Create proxy actor <class 'secretflow.ml.nn.sl.backend.torch.strategy.split_nn.PYUSLTorchModel'> with party bob.\n",
      "\u001b[2m\u001b[36m(pid=52504)\u001b[0m 2023-10-09 17:41:44.002724: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=52504)\u001b[0m 2023-10-09 17:41:44.002863: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=52504)\u001b[0m 2023-10-09 17:41:44.002893: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\u001b[2m\u001b[36m(pid=52569)\u001b[0m 2023-10-09 17:41:44.247772: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=52569)\u001b[0m 2023-10-09 17:41:44.247923: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "\u001b[2m\u001b[36m(pid=52569)\u001b[0m 2023-10-09 17:41:44.247940: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Evaluate Processing::   0%|          | 0/79 [00:00<?, ?it/s]\u001b[2m\u001b[36m(PYUSLTorchModel pid=52569)\u001b[0m /home/zhd/anaconda3/envs/sf-new/lib/python3.8/site-packages/secretflow/ml/nn/sl/backend/torch/sl_base.py:631: UserWarning: The given NumPy array is not writable, and PyTorch does not support non-writable tensors. This means writing to this tensor will result in undefined behavior. You may want to copy the array to protect its data or make it writable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at ../torch/csrc/utils/tensor_numpy.cpp:206.)\n",
      "\u001b[2m\u001b[36m(PYUSLTorchModel pid=52569)\u001b[0m   torch.as_tensor(e)\n",
      "Evaluate Processing:: 100%|██████████| 79/79 [00:01<00:00, 46.75it/s, val_loss:0.3850078284740448 MulticlassAccuracy:0.8077999949455261 MulticlassPrecision:0.8077999949455261 MulticlassAUROC:0.9485939145088196]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAGwCAYAAABVdURTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAyIElEQVR4nO3de1wV9b7/8fcCBEQE71wSwzqa9ytCeMudJKnHsptmnjQre7TTfirbQvOWtpO0Y9vjZWdapp1HHW3vtIuapVSaSl4w3LVTM1Nxm6BmgmKCsub3h9tVSy6upcDgl9fz8Vjp+s53Zj4zwpp335k147AsyxIAAIAhfOwuAAAAoCwRbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjOJndwEVzel06qefflLNmjXlcDjsLgcAAHjAsiydPn1akZGR8vEpfWymyoWbn376SVFRUXaXAQAArsLhw4fVsGHDUvtUuXBTs2ZNSRd3TkhIiM3VAAAAT+Tm5ioqKsp1HC9NlQs3l05FhYSEEG4AALjOeHJJCRcUAwAAoxBuAACAUQg3AADAKFXumhsAALxRWFio8+fP211GleDv73/Fr3l7gnADAEAxLMtSVlaWTp06ZXcpVYaPj48aN24sf3//a1oO4QYAgGJcCjYNGjRQUFAQN34tZ5dusnv06FE1atTomvY34QYAgMsUFha6gk3dunXtLqfKqF+/vn766SdduHBB1apVu+rlcEExAACXuXSNTVBQkM2VVC2XTkcVFhZe03IINwAAlIBTURWrrPY34QYAABiFcAMAAIxCuAEAAOUmOjpas2fPrtB1Em4AAKhCDh48KIfDoYyMDLf2Rx55RP3797elprJGuAEAAEYh3AAA4AHLsnS24IItL8uyvKp17dq16tq1q2rVqqW6devqP//zP7V//35JUuPGjSVJ7du3l8PhUI8ePfT8889r6dKl+uCDD+RwOORwOPTFF19IkpKTk9W0aVMFBQXppptu0qRJk4o8juKjjz5Sp06dFBgYqHr16umee+4psbbXX39dtWrVUmpqqlfb5A1u4gcAgAd+PV+oFpM/sWXd301LVJC/54fsvLw8JSUlqU2bNjpz5owmT56se+65RxkZGdq2bZtiY2O1fv16tWzZUv7+/vL399fu3buVm5urN998U5JUp04dSVLNmjW1ZMkSRUZG6ptvvtHw4cNVs2ZNPfvss5Kk1atX65577tGECRP01ltvqaCgQGvWrCm2rpkzZ2rmzJn69NNPFRsbe417pWSEGwAADHPfffe5vV+8eLHq16+v7777TvXr15ck1a1bV+Hh4a4+1atXV35+vlubJE2cONH19+joaI0dO1bLli1zhZsXX3xRDz74oKZOnerq17Zt2yI1JScn63//93+1YcMGtWzZ8to3shSEGwAAPFC9mq++m5Zo27q9sW/fPk2ePFlbt27ViRMn5HQ6JUmZmZlq0aKFV8tavny55syZo/379+vMmTO6cOGCQkJCXNMzMjI0fPjwUpcxa9Ys5eXlaceOHbrpppu8Wv/V4JobAAA84HA4FOTvZ8vL2zv39uvXTydPntSiRYu0detWbd26VZJUUFDg1XLS0tI0ePBg9enTR6tWrdLXX3+tCRMmuC2nevXqV1xOt27dVFhYqHfffder9V8tRm4AADDIzz//rL1792rRokXq1q2bJGnTpk2u6SU9v8nf379I25YtW3TjjTdqwoQJrrZDhw659WnTpo1SU1M1bNiwEmuKjY3VyJEjdeedd8rPz09jx469uo3zEOEGAACD1K5dW3Xr1tXChQsVERGhzMxMjRs3zjW9QYMGql69utauXauGDRsqMDBQoaGhio6O1ieffKK9e/eqbt26Cg0NVZMmTZSZmally5apU6dOWr16tVauXOm2vilTpqhnz566+eab9eCDD+rChQtas2aNkpOT3fp17txZa9asUe/eveXn56fRo0eX2z7gtBQAAAbx8fHRsmXLlJ6erlatWmnMmDF6+eWXXdP9/Pw0Z84cvfbaa4qMjNTdd98tSRo+fLhuueUWxcTEqH79+tq8ebPuuusujRkzRiNHjlS7du20ZcsWTZo0yW19PXr00N/+9jd9+OGHateunW6//XZt27at2Nq6du2q1atXa+LEiZo7d2657QOH5e2X569zubm5Cg0NVU5OjtsFUQAAXHLu3DkdOHBAjRs3VmBgoN3lVBml7Xdvjt+M3AAAAKMQbgAAgFEINwAAwCiEGwAASlDFLku1XVntb1vDzcaNG9WvXz9FRkbK4XDo/fffv+I8X3zxhTp06KCAgAD9x3/8h5YsWVLudQIAqpZq1apJks6ePWtzJVXLpZsD+vp6d0fmy9l6n5u8vDy1bdtWjz76qO69994r9j9w4ID69u2rJ598Um+//bZSU1P1+OOPKyIiQomJ9twSGwBgHl9fX9WqVUvHjh2TJAUFBXl9l2B4x+l06vjx4woKCpKf37XFE1vDTe/evdW7d2+P+y9YsECNGzfWrFmzJEnNmzfXpk2b9Je//MX2cFPotFRwwVmk3VLxQ2wljbyVNCBX0lDdlQbwHLp4y/CLf0oOOS7++fu/X96HX2DYyLIsWdbFn23Lsv7958XfpUu/BkXeX9ZXv5te3HIuzXT5si/1LU1Jvx/FtZb0q+QotnfJ/YtTXJnl/XnjLW8/Syr6k+dKW2kFhson8Lx+Oprl3T/OVTDtU9chycfH+63y8fFRo0aNrvk4dF3doTgtLU0JCQlubYmJiaXe5TA/P1/5+fmu97m5ueVS265/ndK9f91SLsu2S7HB5wrhSL9//7u/X/qwvPRhYlkq0nbpYHNx+m/TfjuAWb/N6zbPb+2/zVN0fb/frn+XWmTbfqv/Up/St7Gk/SS3+YpfVokHble9JRyc//33y/dXcQfqkg7yl+8TACUL9HOodqCPruJYXWW1iAjR3Ic6eD2fv7+/fHyu/YqZ6yrcZGVlKSwszK0tLCxMubm5+vXXX4t9eFdKSorbY9jhud8OkL8/Cl7/R8TfhwjTtg2e8STglqTUn5JSJpY0qiKVHjQtlV5Paf+DW9II0b8nXs0kj3n92+TFDJas0retOF50v7yrJenkufL7fCizJZfTz1/J85U8NTxftt788LoKN1dj/PjxSkpKcr3Pzc1VVFRUma+nbcNa+m5a8afGymIIurT+JS2/pGH8S/8H7/Rk+L6EoXun0ypxucWNPPx+BOPSR4fjdwcR1yiI3Ec6Lt9u1zSH43fzFu3rcP3HfZrbKFAppyUu32+//b3kbXRbzu/WU9K/weWjYe71lzRC9u+pl48mlbCsYkfdLts3leUspGV5EDpKGE2U5L7dnHIFqrTrKtyEh4crOzvbrS07O1shISElPnI9ICBAAQEB5V6br49DQf7X1e4EAMBI19V9buLj45WamurWtm7dOsXHx9tUEQAAqGxsDTdnzpxRRkaGMjIyJF38qndGRoYyMzMlXTylNGTIEFf/J598Uj/++KOeffZZ7dmzR3/961/17rvvasyYMXaUDwAAKiFbw82OHTvUvn17tW/fXpKUlJSk9u3ba/LkyZKko0ePuoKOJDVu3FirV6/WunXr1LZtW82aNUuvv/667V8DBwAAlYfDqmL3lvbmkekAAKBy8Ob4fV1dcwMAAHAlhBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFFsDzfz589XdHS0AgMDFRcXp23btpXaf/bs2brllltUvXp1RUVFacyYMTp37lwFVQsAACo7W8PN8uXLlZSUpClTpmjnzp1q27atEhMTdezYsWL7v/POOxo3bpymTJmi3bt364033tDy5cv13HPPVXDlAACgsrI13LzyyisaPny4hg0bphYtWmjBggUKCgrS4sWLi+2/ZcsWdenSRQ899JCio6PVq1cvDRo06IqjPQAAoOqwLdwUFBQoPT1dCQkJvxXj46OEhASlpaUVO0/nzp2Vnp7uCjM//vij1qxZoz59+pS4nvz8fOXm5rq9AACAufzsWvGJEydUWFiosLAwt/awsDDt2bOn2HkeeughnThxQl27dpVlWbpw4YKefPLJUk9LpaSkaOrUqWVaOwAAqLxsv6DYG1988YWmT5+uv/71r9q5c6dWrFih1atX64UXXihxnvHjxysnJ8f1Onz4cAVWDAAAKpptIzf16tWTr6+vsrOz3dqzs7MVHh5e7DyTJk3Sww8/rMcff1yS1Lp1a+Xl5emJJ57QhAkT5ONTNKsFBAQoICCg7DcAAABUSraN3Pj7+6tjx45KTU11tTmdTqWmpio+Pr7Yec6ePVskwPj6+kqSLMsqv2IBAMB1w7aRG0lKSkrS0KFDFRMTo9jYWM2ePVt5eXkaNmyYJGnIkCG64YYblJKSIknq16+fXnnlFbVv315xcXH64YcfNGnSJPXr188VcgAAQNVma7gZOHCgjh8/rsmTJysrK0vt2rXT2rVrXRcZZ2Zmuo3UTJw4UQ6HQxMnTtSRI0dUv3599evXTy+++KJdmwAAACoZh1XFzufk5uYqNDRUOTk5CgkJsbscAADgAW+O39fVt6UAAACuhHADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwylWFmwsXLmj9+vV67bXXdPr0aUnSTz/9pDNnzpRpcQAAAN7y83aGQ4cO6c4771RmZqby8/N1xx13qGbNmpoxY4by8/O1YMGC8qgTAADAI16P3IwaNUoxMTH65ZdfVL16dVf7Pffco9TU1DItDgAAwFtej9x8+eWX2rJli/z9/d3ao6OjdeTIkTIrDAAA4Gp4PXLjdDpVWFhYpP1f//qXatasWSZFAQAAXC2vw02vXr00e/Zs13uHw6EzZ85oypQp6tOnT1nWBgAA4DWHZVmWNzMcPnxYd955pyzL0r59+xQTE6N9+/apXr162rhxoxo0aFBetZaJ3NxchYaGKicnRyEhIXaXAwAAPODN8dvrcCNd/Cr48uXLtWvXLp05c0YdOnTQ4MGD3S4wrqwINwAAXH/KLdycP39ezZo106pVq9S8efNrLtQOhBsAAK4/3hy/vbrmplq1ajp37tw1FXe5+fPnKzo6WoGBgYqLi9O2bdtK7X/q1CmNGDFCERERCggIUNOmTbVmzZoyrQkAAFy/vL6geMSIEZoxY4YuXLhwzStfvny5kpKSNGXKFO3cuVNt27ZVYmKijh07Vmz/goIC3XHHHTp48KD+/ve/a+/evVq0aJFuuOGGa64FAACYwetrbi7drC84OFitW7dWjRo13KavWLHC42XFxcWpU6dOmjdvnqSLXzOPiorS008/rXHjxhXpv2DBAr388svas2ePqlWr5tE68vPzlZ+f73qfm5urqKgoTksBAHAdKbfTUpJUq1Yt3XfffUpMTFRkZKRCQ0PdXp4qKChQenq6EhISfivGx0cJCQlKS0srdp4PP/xQ8fHxGjFihMLCwtSqVStNnz692PvuXJKSkuJWX1RUlOcbCwAArjte36H4zTffLJMVnzhxQoWFhQoLC3NrDwsL0549e4qd58cff9Rnn32mwYMHa82aNfrhhx/01FNP6fz585oyZUqx84wfP15JSUmu95dGbgAAgJm8DjeXHD9+XHv37pUk3XLLLapfv36ZFVUSp9OpBg0aaOHChfL19VXHjh115MgRvfzyyyWGm4CAAAUEBJR7bQAAoHLw+rRUXl6eHn30UUVERKh79+7q3r27IiMj9dhjj+ns2bMeL6devXry9fVVdna2W3t2drbCw8OLnSciIkJNmzaVr6+vq6158+bKyspSQUGBt5sCAAAM5HW4SUpK0oYNG/TRRx/p1KlTOnXqlD744ANt2LBBf/rTnzxejr+/vzp27Oj2JHGn06nU1FTFx8cXO0+XLl30ww8/yOl0utq+//57RUREFHmQJwAAqJq8Djfvvfee3njjDfXu3VshISEKCQlRnz59tGjRIv3973/3allJSUlatGiRli5dqt27d+uPf/yj8vLyNGzYMEnSkCFDNH78eFf/P/7xjzp58qRGjRql77//XqtXr9b06dM1YsQIbzcDAAAYyutrbs6ePVvkImBJatCggVenpSRp4MCBOn78uCZPnqysrCy1a9dOa9eudS0/MzNTPj6/5a+oqCh98sknGjNmjNq0aaMbbrhBo0aNUnJysrebAQAADOX1fW569uypunXr6q233lJgYKAk6ddff9XQoUN18uRJrV+/vlwKLSs8fgEAgOuPN8dvr0du/ud//keJiYlq2LCh2rZtK0natWuXAgMD9cknn1xdxQAAAGXkqp4KfvbsWb399tuu+9E0b96cp4IDAIByU64jN5IUFBSk4cOHX1VxAAAA5cnrb0ulpKRo8eLFRdoXL16sGTNmlElRAAAAV8vrcPPaa6+pWbNmRdpbtmypBQsWlElRAAAAV8vrcJOVlaWIiIgi7fXr19fRo0fLpCgAAICr5XW4iYqK0ubNm4u0b968WZGRkWVSFAAAwNXy+oLi4cOHa/To0Tp//rxuv/12SVJqaqqeffZZrx6/AAAAUB68DjfPPPOMfv75Zz311FOuh1UGBgYqOTnZ7VEJAAAAdriq+9xI0pkzZ7R7925Vr15dTZo0UUBAQFnXVi64zw0AANcfb47fXl9zc0lwcLA6deqkRo0a6eOPP9bu3buvdlEAAABlxutwM2DAAM2bN0/SxWdKxcTEaMCAAWrTpo3ee++9Mi8QAADAG16Hm40bN6pbt26SpJUrV8qyLJ06dUpz5szRn//85zIvEAAAwBteh5ucnBzVqVNHkrR27Vrdd999CgoKUt++fbVv374yLxAAAMAbV3Wfm7S0NOXl5Wnt2rXq1auXJOmXX35RYGBgmRcIAADgDa+/Cj569GgNHjxYwcHBuvHGG9WjRw9JF09XtW7duqzrAwAA8IrX4eapp55SXFycMjMzdccdd8jH5+Lgz0033cQ1NwAAwHZXfZ+b6xX3uQEA4PpTIfe5AQAAqIwINwAAwCiEGwAAYBTCDQAAMIpX35bKzc11XcSzZs0aXbhwwTXN19dXffv2LdvqAAAAvORxuFm1apUmTZqkr7/+WpI0cOBA5eXluaY7HA4tX75c999/f9lXCQAA4CGPT0stXLhQTz/9tFvbDz/8IKfTKafTqZSUFC1evLjMCwQAAPCGx+Hmm2++UZcuXUqc3rt3b+3YsaNMigIAALhaHoebo0ePKiAgwPX+888/V1RUlOt9cHCwcnJyyrY6AAAAL3kcburUqaMffvjB9T4mJkbVqlVzvd+3b5/raeEAAAB28TjcdO/eXXPmzClx+pw5c9S9e/cyKQoAAOBqeRxukpOT9emnn+qBBx7Q9u3blZOTo5ycHG3btk333Xef1q9fr+Tk5PKsFQAA4Io8/ip4+/bttXz5cj3++ONasWKF27TatWtr2bJl6tChQ5kXCAAA4A2vnwp+9uxZffLJJ9q3b58kqUmTJurVq5dq1KhRLgWWNZ4KDgDA9ceb47dXdyiWpKCgIN1zzz1XXRwAAEB58viam7S0NK1atcqt7a233lLjxo3VoEEDPfHEE8rPzy/zAgEAALzhcbiZNm2a/vnPf7ref/PNN3rssceUkJCgcePG6aOPPlJKSkq5FAkAAOApj8NNRkaGevbs6Xq/bNkyxcXFadGiRUpKStKcOXP07rvvlkuRAAAAnvI43Pzyyy8KCwtzvd+wYYN69+7tet+pUycdPny4bKsDAADwksfhJiwsTAcOHJAkFRQUaOfOnbr11ltd00+fPu12x2IAAAA7eBxu+vTpo3HjxunLL7/U+PHjFRQUpG7durmm/+Mf/9DNN99cLkUCAAB4yuOvgr/wwgu69957ddtttyk4OFhLly6Vv7+/a/rixYvVq1evcikSAADAU17fxC8nJ0fBwcHy9fV1az958qSCg4PdAk9lxE38AAC4/pTrTfxCQ0OLbeeJ4AAAoDLw+JobAACA6wHhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRKkW4mT9/vqKjoxUYGKi4uDht27bNo/mWLVsmh8Oh/v37l2+BAADgumF7uFm+fLmSkpI0ZcoU7dy5U23btlViYqKOHTtW6nwHDx7U2LFj1a1btwqqFAAAXA9sDzevvPKKhg8frmHDhqlFixZasGCBgoKCtHjx4hLnKSws1ODBgzV16lTddNNNpS4/Pz9fubm5bi8AAGAuW8NNQUGB0tPTlZCQ4Grz8fFRQkKC0tLSSpxv2rRpatCggR577LErriMlJUWhoaGuV1RUVJnUDgAAKidbw82JEydUWFiosLAwt/awsDBlZWUVO8+mTZv0xhtvaNGiRR6tY/z48crJyXG9Dh8+fM11AwCAysvP7gK8cfr0aT388MNatGiR6tWr59E8AQEBCggIKOfKAABAZWFruKlXr558fX2VnZ3t1p6dna3w8PAi/ffv36+DBw+qX79+rjan0ylJ8vPz0969e3XzzTeXb9EAAKBSs/W0lL+/vzp27KjU1FRXm9PpVGpqquLj44v0b9asmb755htlZGS4XnfddZf+8Ic/KCMjg+tpAACA/aelkpKSNHToUMXExCg2NlazZ89WXl6ehg0bJkkaMmSIbrjhBqWkpCgwMFCtWrVym79WrVqSVKQdAABUTbaHm4EDB+r48eOaPHmysrKy1K5dO61du9Z1kXFmZqZ8fGz/xjoAALhOOCzLsuwuoiLl5uYqNDRUOTk5CgkJsbscAADgAW+O3wyJAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGqRThZv78+YqOjlZgYKDi4uK0bdu2EvsuWrRI3bp1U+3atVW7dm0lJCSU2h8AAFQttoeb5cuXKykpSVOmTNHOnTvVtm1bJSYm6tixY8X2/+KLLzRo0CB9/vnnSktLU1RUlHr16qUjR45UcOUAAKAycliWZdlZQFxcnDp16qR58+ZJkpxOp6KiovT0009r3LhxV5y/sLBQtWvX1rx58zRkyJAr9s/NzVVoaKhycnIUEhJyzfUDAIDy583x29aRm4KCAqWnpyshIcHV5uPjo4SEBKWlpXm0jLNnz+r8+fOqU6dOsdPz8/OVm5vr9gIAAOayNdycOHFChYWFCgsLc2sPCwtTVlaWR8tITk5WZGSkW0D6vZSUFIWGhrpeUVFR11w3AACovGy/5uZavPTSS1q2bJlWrlypwMDAYvuMHz9eOTk5rtfhw4cruEoAAFCR/Oxceb169eTr66vs7Gy39uzsbIWHh5c673//93/rpZde0vr169WmTZsS+wUEBCggIKBM6gUAAJWfrSM3/v7+6tixo1JTU11tTqdTqampio+PL3G+mTNn6oUXXtDatWsVExNTEaUCAIDrhK0jN5KUlJSkoUOHKiYmRrGxsZo9e7by8vI0bNgwSdKQIUN0ww03KCUlRZI0Y8YMTZ48We+8846io6Nd1+YEBwcrODjYtu0AAACVg+3hZuDAgTp+/LgmT56srKwstWvXTmvXrnVdZJyZmSkfn98GmF599VUVFBTo/vvvd1vOlClT9Pzzz1dk6QAAoBKy/T43FY373AAAcP25bu5zAwAAUNYINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAACAUQg3AADAKIQbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABiFcAMAAIxCuAEAAEYh3AAAAKMQbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAo1SKcDN//nxFR0crMDBQcXFx2rZtW6n9//a3v6lZs2YKDAxU69attWbNmgqqFAAAVHa2h5vly5crKSlJU6ZM0c6dO9W2bVslJibq2LFjxfbfsmWLBg0apMcee0xff/21+vfvr/79++vbb7+t4MoBAEBl5LAsy7KzgLi4OHXq1Enz5s2TJDmdTkVFRenpp5/WuHHjivQfOHCg8vLytGrVKlfbrbfeqnbt2mnBggVXXF9ubq5CQ0OVk5OjkJCQstsQAABQbrw5fvtVUE3FKigoUHp6usaPH+9q8/HxUUJCgtLS0oqdJy0tTUlJSW5tiYmJev/994vtn5+fr/z8fNf7nJwcSRd3EgAAuD5cOm57MiZja7g5ceKECgsLFRYW5tYeFhamPXv2FDtPVlZWsf2zsrKK7Z+SkqKpU6cWaY+KirrKqgEAgF1Onz6t0NDQUvvYGm4qwvjx491GepxOp06ePKm6devK4XCU6bpyc3MVFRWlw4cPc8rr39gnxWO/FMU+KYp9Ujz2S1FVYZ9YlqXTp08rMjLyin1tDTf16tWTr6+vsrOz3dqzs7MVHh5e7Dzh4eFe9Q8ICFBAQIBbW61ata6+aA+EhIQY+8N1tdgnxWO/FMU+KYp9Ujz2S1Gm75MrjdhcYuu3pfz9/dWxY0elpqa62pxOp1JTUxUfH1/sPPHx8W79JWndunUl9gcAAFWL7aelkpKSNHToUMXExCg2NlazZ89WXl6ehg0bJkkaMmSIbrjhBqWkpEiSRo0apdtuu02zZs1S3759tWzZMu3YsUMLFy60czMAAEAlYXu4GThwoI4fP67JkycrKytL7dq109q1a10XDWdmZsrH57cBps6dO+udd97RxIkT9dxzz6lJkyZ6//331apVK7s2wSUgIEBTpkwpchqsKmOfFI/9UhT7pCj2SfHYL0WxT9zZfp8bAACAsmT7HYoBAADKEuEGAAAYhXADAACMQrgBAABGIdyUkfnz5ys6OlqBgYGKi4vTtm3b7C7JVikpKerUqZNq1qypBg0aqH///tq7d6/dZVUqL730khwOh0aPHm13KbY6cuSI/uu//kt169ZV9erV1bp1a+3YscPusmxVWFioSZMmqXHjxqpevbpuvvlmvfDCCx49U8cUGzduVL9+/RQZGSmHw1Hk+YGWZWny5MmKiIhQ9erVlZCQoH379tlTbAUqbb+cP39eycnJat26tWrUqKHIyEgNGTJEP/30k30F24RwUwaWL1+upKQkTZkyRTt37lTbtm2VmJioY8eO2V2abTZs2KARI0boq6++0rp163T+/Hn16tVLeXl5dpdWKWzfvl2vvfaa2rRpY3cptvrll1/UpUsXVatWTR9//LG+++47zZo1S7Vr17a7NFvNmDFDr776qubNm6fdu3drxowZmjlzpubOnWt3aRUmLy9Pbdu21fz584udPnPmTM2ZM0cLFizQ1q1bVaNGDSUmJurcuXMVXGnFKm2/nD17Vjt37tSkSZO0c+dOrVixQnv37tVdd91lQ6U2s3DNYmNjrREjRrjeFxYWWpGRkVZKSoqNVVUux44dsyRZGzZssLsU250+fdpq0qSJtW7dOuu2226zRo0aZXdJtklOTra6du1qdxmVTt++fa1HH33Ure3ee++1Bg8ebFNF9pJkrVy50vXe6XRa4eHh1ssvv+xqO3XqlBUQEGD93//9nw0V2uPy/VKcbdu2WZKsQ4cOVUxRlQQjN9eooKBA6enpSkhIcLX5+PgoISFBaWlpNlZWueTk5EiS6tSpY3Ml9hsxYoT69u3r9jNTVX344YeKiYnRAw88oAYNGqh9+/ZatGiR3WXZrnPnzkpNTdX3338vSdq1a5c2bdqk3r1721xZ5XDgwAFlZWW5/Q6FhoYqLi6Oz93L5OTkyOFwlPszFSsb2+9QfL07ceKECgsLXXdUviQsLEx79uyxqarKxel0avTo0erSpUuluJO0nZYtW6adO3dq+/btdpdSKfz444969dVXlZSUpOeee07bt2/X//t//0/+/v4aOnSo3eXZZty4ccrNzVWzZs3k6+urwsJCvfjiixo8eLDdpVUKWVlZklTs5+6laZDOnTun5ORkDRo0yOiHaRaHcINyN2LECH377bfatGmT3aXY6vDhwxo1apTWrVunwMBAu8upFJxOp2JiYjR9+nRJUvv27fXtt99qwYIFVTrcvPvuu3r77bf1zjvvqGXLlsrIyNDo0aMVGRlZpfcLPHf+/HkNGDBAlmXp1VdftbucCsdpqWtUr149+fr6Kjs72609Oztb4eHhNlVVeYwcOVKrVq3S559/roYNG9pdjq3S09N17NgxdejQQX5+fvLz89OGDRs0Z84c+fn5qbCw0O4SK1xERIRatGjh1ta8eXNlZmbaVFHl8Mwzz2jcuHF68MEH1bp1az388MMaM2aM6wHCVd2lz1Y+d4t3KdgcOnRI69atq3KjNhLh5pr5+/urY8eOSk1NdbU5nU6lpqYqPj7exsrsZVmWRo4cqZUrV+qzzz5T48aN7S7Jdj179tQ333yjjIwM1ysmJkaDBw9WRkaGfH197S6xwnXp0qXILQK+//573XjjjTZVVDmcPXvW7YHBkuTr6yun02lTRZVL48aNFR4e7va5m5ubq61bt1bpz13pt2Czb98+rV+/XnXr1rW7JFtwWqoMJCUlaejQoYqJiVFsbKxmz56tvLw8DRs2zO7SbDNixAi98847+uCDD1SzZk3XefDQ0FBVr17d5ursUbNmzSLXHNWoUUN169atstcijRkzRp07d9b06dM1YMAAbdu2TQsXLtTChQvtLs1W/fr104svvqhGjRqpZcuW+vrrr/XKK6/o0Ucftbu0CnPmzBn98MMPrvcHDhxQRkaG6tSpo0aNGmn06NH685//rCZNmqhx48aaNGmSIiMj1b9/f/uKrgCl7ZeIiAjdf//92rlzp1atWqXCwkLXZ2+dOnXk7+9vV9kVz+6va5li7ty5VqNGjSx/f38rNjbW+uqrr+wuyVaSin29+eabdpdWqVT1r4JblmV99NFHVqtWrayAgACrWbNm1sKFC+0uyXa5ubnWqFGjrEaNGlmBgYHWTTfdZE2YMMHKz8+3u7QK8/nnnxf7GTJ06FDLsi5+HXzSpElWWFiYFRAQYPXs2dPau3evvUVXgNL2y4EDB0r87P3888/tLr1COSyrCt3yEgAAGI9rbgAAgFEINwAAwCiEGwAAYBTCDQAAMArhBgAAGIVwAwAAjEK4AQAARiHcAAAAoxBuAJSLs2fP6r777lNISIgcDodOnTpVbL+FCxcqKipKPj4+mj17tkfLjo6O9rivJ5YsWaJatWqV2fK80aNHD40ePdqWdQOmItwAhnjkkUfkcDj00ksvubW///77cjgcFV7P0qVL9eWXX2rLli06evSoQkNDi/TJzc3VyJEjlZycrCNHjuiJJ56o8DrLUlmHLgBXh3ADGCQwMFAzZszQL7/8Yncp2r9/v5o3b65WrVopPDy82ICVmZmp8+fPq2/fvoqIiFBQUJANlQIwDeEGMEhCQoLCw8OVkpJSar/33ntPLVu2VEBAgKKjozVr1iyv11XaMnr06KFZs2Zp48aNcjgc6tGjR5H5lyxZotatW0uSbrrpJjkcDh08eFD79+/X3XffrbCwMAUHB6tTp05av359qbW8/vrrqlWrllJTUyVJ3377rXr37q3g4GCFhYXp4Ycf1okTJ664Te+//76aNGmiwMBAJSYm6vDhw65pV6qrR48eOnTokMaMGSOHw+EW5jZv3qwePXooKChItWvXVmJiolsAdTqdevbZZ1WnTh2Fh4fr+eefd6vr1KlTevzxx1W/fn2FhITo9ttv165du1zTd+3apT/84Q+qWbOmQkJC1LFjR+3YseOK2wuYinADGMTX11fTp0/X3Llz9a9//avYPunp6RowYIAefPBBffPNN3r++ec1adIkLVmyxOP1XGkZK1as0PDhwxUfH6+jR49qxYoVRZYxcOBAVzjYtm2bjh49qqioKJ05c0Z9+vRRamqqvv76a915553q16+fMjMzi61l5syZGjdunD799FP17NlTp06d0u2336727dtrx44dWrt2rbKzszVgwIBSt+ns2bN68cUX9dZbb2nz5s06deqUHnzwQdf0K9W1YsUKNWzYUNOmTdPRo0d19OhRSVJGRoZ69uypFi1aKC0tTZs2bVK/fv1UWFjoWvbSpUtVo0YNbd26VTNnztS0adO0bt061/QHHnhAx44d08cff6z09HR16NBBPXv21MmTJyVJgwcPVsOGDbV9+3alp6dr3Lhxqlat2pX+GQFz2f1YcgBlY+jQodbdd99tWZZl3Xrrrdajjz5qWZZlrVy50vr9r/pDDz1k3XHHHW7zPvPMM1aLFi08Xpcnyxg1apR12223lbqcr7/+2pJkHThwoNR+LVu2tObOnet6f+ONN1p/+ctfrGeffdaKiIiwvv32W9e0F154werVq5fb/IcPH7YkWXv37i12+W+++aYlyfrqq69cbbt377YkWVu3bvW6rt8bNGiQ1aVLlxKXcdttt1ldu3Z1a+vUqZOVnJxsWZZlffnll1ZISIh17tw5tz4333yz9dprr1mWZVk1a9a0lixZUuI6gKqGkRvAQDNmzNDSpUu1e/fuItN2796tLl26uLV16dJF+/btcxtNKE1ZLKMkZ86c0dixY9W8eXPVqlVLwcHB2r17d5GRm1mzZmnRokXatGmTWrZs6WrftWuXPv/8cwUHB7tezZo1k3Tx1FJJ/Pz81KlTJ9f7Zs2aqVatWq596Gldl7s0clOaNm3auL2PiIjQsWPHXNtz5swZ1a1b122bDhw44NqepKQkPf7440pISNBLL71U6nYCVQHhBjBQ9+7dlZiYqPHjx9tditfGjh2rlStXavr06fryyy+VkZGh1q1bq6CgwK1ft27dVFhYqHfffdet/cyZM+rXr58yMjLcXvv27VP37t3Lva7LVa9e/YrLvvwUksPhkNPpdG1PREREke3Zu3evnnnmGUnS888/r3/+85/q27evPvvsM7Vo0UIrV668yi0Frn9+dhcAoHy89NJLateunW655Ra39ubNm2vz5s1ubZs3b1bTpk3l6+vr0bLLYhkl2bx5sx555BHdc889ki4e3A8ePFikX2xsrEaOHKk777xTfn5+Gjt2rCSpQ4cOeu+99xQdHS0/P88/4i5cuKAdO3YoNjZWkrR3716dOnVKzZs397guf3//IiNXbdq0UWpqqqZOnepxLb/XoUMHZWVlyc/PT9HR0SX2a9q0qZo2baoxY8Zo0KBBevPNN121AlUNIzeAoVq3bq3Bgwdrzpw5bu1/+tOflJqaqhdeeEHff/+9li5dqnnz5rnCgST17NlT8+bNK3HZnizjajVp0kQrVqxQRkaGdu3apYceesg1inG5zp07a82aNZo6darr/jIjRozQyZMnNWjQIG3fvl379+/XJ598omHDhpV6yqxatWp6+umntXXrVqWnp+uRRx7Rrbfe6go7ntQVHR2tjRs36siRI65vZ40fP17bt2/XU089pX/84x/as2ePXn31VY++vSVd/AZcfHy8+vfvr08//VQHDx7Uli1bNGHCBO3YsUO//vqrRo4cqS+++EKHDh3S5s2btX37dlcoA6oiwg1gsGnTphU5AHfo0EHvvvuuli1bplatWmny5MmaNm2aHnnkEVef/fv3l3rw9WQZV+uVV15R7dq11blzZ/Xr10+JiYnq0KFDif27du2q1atXa+LEiZo7d64iIyO1efNmFRYWqlevXmrdurVGjx6tWrVqycen5I+8oKAgJScn66GHHlKXLl0UHBys5cuXe1XXtGnTdPDgQd18882qX7++pIsjKp9++ql27dql2NhYxcfH64MPPvB4VMnhcGjNmjXq3r27hg0bpqZNm+rBBx/UoUOHFBYWJl9fX/38888aMmSImjZtqgEDBqh3795XPVIEmMBhWZZldxEAAABlhZEbAABgFMINAAAwCuEGAAAYhXADAACMQrgBAABGIdwAAACjEG4AAIBRCDcAAMAohBsAAGAUwg0AADAK4QYAABjl/wNOzyn0yfMmNwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_torch_model(partys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sfmod",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
